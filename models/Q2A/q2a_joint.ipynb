{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('allseasons.csv')\n",
    "df=df.drop(['Unnamed: 0'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Temperature, salinity, and stratification avg by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Surface_Temp', 'Surface_Salinity', 'Bottom_Temp', 'Bottom_Salinity', 'temp_strat', 'salt_strat']\n",
    "\n",
    "##change based off season\n",
    "sliced_df=df.loc[df['sampling_bout']=='Jun_23']\n",
    "# sliced_df=df.loc[df['sampling_bout']=='Aug_23']\n",
    "sliced_df=df.loc[df['sampling_bout']=='Feb_24']\n",
    "summary_stats = sliced_df[columns].describe()\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Surface Temp (Feb, June, Aug): 5.88, 16.62, 22.23  \n",
    "Average Surface Salinity: 28.815, 29.741, 30.581  \n",
    "Average Temperature Stratification: 0.281, 2.518, 4.739"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Dimensionality Reduction using PCA/tSNE on Dataset (*with Oceanographic Data*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_asvs = df.iloc[:, 11:]\n",
    "fish_asvs\n",
    "tsne_df = df\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=20, perplexity=20, learning_rate=5, n_iter=300) #test with diff perplexity\n",
    "tsne_result = tsne.fit_transform(fish_asvs)\n",
    "# Perform t-SNE\n",
    "\n",
    "# Add t-SNE results to the dataframe\n",
    "tsne_df['tSNE1'] = tsne_result[:, 0]\n",
    "tsne_df['tSNE2'] = tsne_result[:, 1]\n",
    "tsne_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='tSNE1', y='tSNE2', data=tsne_df, hue='date', s=100, palette='tab10')\n",
    "\n",
    "plt.title('tSNE of Fish ASVs colored by date')\n",
    "plt.xlabel('tSNE Component 1')\n",
    "plt.ylabel('tSNE Component 2')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifications for model: keep date, oceanographic variables.\n",
    "If date is a strong predictor, influence of migratory species may be too high! Remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_move = df.pop(\"date\")\n",
    "# insert column with insert(location, column_name, column_value)\n",
    "\n",
    "df.insert(92, \"date\", column_to_move)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep date - modify existing code\n",
    "## Plot feature importance\n",
    "ml_df = df.iloc[:,10:] # type: ignore\n",
    "ml_df = ml_df.drop(['tSNE1','tSNE2'],axis=1)\n",
    "ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df['date'] = pd.to_datetime(ml_df['date'], format='%m/%d/%y')\n",
    "# Convert datetime to timestamp (e.g., number of days since a reference date)\n",
    "ml_df['date_numeric'] = (ml_df['date'] - pd.Timestamp('1970-01-01')) // pd.Timedelta('1D')\n",
    "ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "## MULTI OUTPUT CLASSIFIER\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "features = ml_df[['Surface_Salinity','Bottom_Salinity','salt_strat', 'Surface_Temp','Bottom_Temp','temp_strat']]\n",
    "\n",
    "labels = ml_df.loc[:,'Atl_croaker_(nibea98)':'Atl_salmon'].applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the multi-output Random Forest classifier\n",
    "rf_classifier = MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "for i, species in enumerate(labels.columns):\n",
    "    accuracy = accuracy_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    # precision = precision_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    # recall = recall_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    # f1 = f1_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Classification report for {species}:\\n\", classification_report(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    # print(f\"Accuracy for {species}: {accuracy}\")\n",
    "\n",
    "# Calculate overall average accuracy across all species\n",
    "average_accuracy = np.mean(accuracies)\n",
    "average_accuracy\n",
    "\n",
    "# # Evaluate the model\n",
    "# for i, species in enumerate(labels.columns):\n",
    "#     print(f\"Classification report for {species}:\\n\", classification_report(y_test.iloc[:, i], y_pred[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot\n",
    "feature_importance_df = pd.DataFrame() # type: ignore\n",
    "for i, species in enumerate(labels.columns):\n",
    "    importances = rf_classifier.estimators_[i].feature_importances_\n",
    "    feature_importance_df[species] = importances\n",
    "\n",
    "# Calculate mean feature importance across all species\n",
    "feature_importance_df['mean_importance'] = feature_importance_df.mean(axis=1)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(features.columns, feature_importance_df['mean_importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Mean Feature Importance Across All Species')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ran without rare species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = len(ml_df) * 0.2\n",
    "\n",
    "# Count the non-zero occurrences of each species\n",
    "species_columns = ml_df.columns[:-10]  # Adjust the slice to exclude non-species columns if needed\n",
    "species_counts = (ml_df[species_columns] > 0).sum()\n",
    "filtered_species = species_counts[species_counts >= threshold].index\n",
    "filtered_df = ml_df[filtered_species]\n",
    "non_species_columns = ml_df.columns[-10:]  # Adjust this if the non-species columns are at the end\n",
    "filtered_df = pd.concat([filtered_df, ml_df[non_species_columns]], axis=1)\n",
    "filtered_df = filtered_df.dropna()\n",
    "\n",
    "filtered_df\n",
    "filtered_ml_df = filtered_df\n",
    "filtered_ml_df.to_csv('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MULTI OUTPUT CLASSIFIER\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "features = filtered_ml_df[['Surface_Temp','Bottom_Temp','Surface_Salinity','Bottom_Salinity','temp_strat','salt_strat']]\n",
    "## with date\n",
    "# features = ml_df[['Surface_Salinity','Bottom_Salinity','salt_strat', 'Surface_Temp','Bottom_Temp','temp_strat','date_numeric']]\n",
    "\n",
    "labels = filtered_ml_df.loc[:,'Atl_croaker_(nibea98)':'Winter_or_Yellowtail_flounder'].applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the multi-output Random Forest classifier\n",
    "rf_classifier = MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42\n",
    "                                                            , min_samples_split=5, min_samples_leaf= 2, max_depth=None, bootstrap=True\n",
    "                                                             ))\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "for i, species in enumerate(labels.columns):\n",
    "    accuracy = accuracy_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    # precision = precision_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    # recall = recall_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    # f1 = f1_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Classification report for {species}:\\n\", classification_report(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    # print(f\"Accuracy for {species}: {accuracy}\")\n",
    "\n",
    "# Calculate overall average accuracy across all species\n",
    "average_accuracy = np.mean(accuracies)\n",
    "average_accuracy\n",
    "\n",
    "# # Evaluate the model\n",
    "# for i, species in enumerate(labels.columns):\n",
    "#     print(f\"Classification report for {species}:\\n\", classification_report(y_test.iloc[:, i], y_pred[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_importance_df = pd.DataFrame() # type: ignore\n",
    "for i, species in enumerate(labels.columns):\n",
    "    importances = rf_classifier.estimators_[i].feature_importances_\n",
    "    feature_importance_df[species] = importances\n",
    "\n",
    "# Calculate mean feature importance across all species\n",
    "feature_importance_df['mean_importance'] = feature_importance_df.mean(axis=1)\n",
    "\n",
    "# # Plot feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(features.columns, feature_importance_df['mean_importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Mean Feature Importance Across All Species')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "importances\n",
    "# feature_importance_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "Finding best combination of weights for model: tbd 7/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomizedsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'estimator__n_estimators' : [50,100,200,500],\n",
    "    'estimator__max_depth': [None, 10, 20, 30],\n",
    "    'estimator__min_samples_split': [2, 5, 10],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4],\n",
    "    'estimator__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_classifier = MultiOutputClassifier(RandomForestClassifier())\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "randomized_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_dist, n_iter=20, cv=3, random_state=42)\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params_rand = randomized_search.best_params_\n",
    "best_model_rand = randomized_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred_best_rand = best_model_rand.predict(X_test)\n",
    "accuracy_best_rand = accuracy_score(y_test, y_pred_best_rand)\n",
    "print(f\"Best RF Accuracy: {accuracy_best_rand:.2f}\")\n",
    "print(f\"Best Hyperparameters: {best_params_rand}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters according to previous grid search: {'estimator__bootstrap': True, 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2}\n",
    "\n",
    "Best Hyperparameters from Random Search: {'estimator__min_samples_split': 5, 'estimator__min_samples_leaf': 2, 'estimator__max_depth': None, 'estimator__bootstrap': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define new grid based on Random search best params above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ml_df[['Surface_Temp','Bottom_Temp','Surface_Salinity','Bottom_Salinity','temp_strat','salt_strat']]\n",
    "labels = ml_df.loc[:,'Atl_croaker_(nibea98)':'Atl_salmon'].applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_classifier = MultiOutputClassifier(RandomForestClassifier(n_estimators=100, min_samples_leaf=2,min_samples_split=5,\n",
    "                                                             max_depth=None,bootstrap=True,random_state=42))\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracies = []\n",
    "for i, species in enumerate(labels.columns):\n",
    "    accuracy = accuracy_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Classification report for {species}:\\n\", classification_report(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    # print(f\"Accuracy for {species}: {accuracy}\")\n",
    "\n",
    "# Calculate overall average accuracy across all species\n",
    "average_accuracy = np.mean(accuracies)\n",
    "average_accuracy\n",
    "## avg accuracy of 88.9%, improvement of 0.1% from default"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
