{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>project</th>\n",
       "      <th>date</th>\n",
       "      <th>sampling_bout</th>\n",
       "      <th>gear</th>\n",
       "      <th>sample_grp</th>\n",
       "      <th>station</th>\n",
       "      <th>location</th>\n",
       "      <th>replicate</th>\n",
       "      <th>primers</th>\n",
       "      <th>...</th>\n",
       "      <th>White_catfish</th>\n",
       "      <th>Atl_salmon</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Surface_Temp</th>\n",
       "      <th>Bottom_Temp</th>\n",
       "      <th>Surface_Salinity</th>\n",
       "      <th>Bottom_Salinity</th>\n",
       "      <th>temp_strat</th>\n",
       "      <th>salt_strat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NJOT_Feb_24_10</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.568000</td>\n",
       "      <td>38.874000</td>\n",
       "      <td>5.956091</td>\n",
       "      <td>5.913677</td>\n",
       "      <td>30.449176</td>\n",
       "      <td>30.469612</td>\n",
       "      <td>0.042414</td>\n",
       "      <td>0.020436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NJOT_Feb_24_11</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>11</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.618000</td>\n",
       "      <td>38.724000</td>\n",
       "      <td>6.265040</td>\n",
       "      <td>6.349604</td>\n",
       "      <td>30.647220</td>\n",
       "      <td>30.878290</td>\n",
       "      <td>0.084564</td>\n",
       "      <td>0.231070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJOT_Feb_24_12</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>12</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.672000</td>\n",
       "      <td>38.728000</td>\n",
       "      <td>6.141931</td>\n",
       "      <td>6.000855</td>\n",
       "      <td>30.286460</td>\n",
       "      <td>30.501550</td>\n",
       "      <td>0.141076</td>\n",
       "      <td>0.215090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NJOT_Feb_24_13</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>13</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.928000</td>\n",
       "      <td>38.905000</td>\n",
       "      <td>5.563858</td>\n",
       "      <td>5.591211</td>\n",
       "      <td>30.637451</td>\n",
       "      <td>30.595319</td>\n",
       "      <td>0.027353</td>\n",
       "      <td>0.042131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NJOT_Feb_24_14</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>14</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.969000</td>\n",
       "      <td>38.843000</td>\n",
       "      <td>5.451434</td>\n",
       "      <td>5.624359</td>\n",
       "      <td>29.023967</td>\n",
       "      <td>30.008847</td>\n",
       "      <td>0.172925</td>\n",
       "      <td>0.984880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>NJOT_Aug_23_93</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>93</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.828700</td>\n",
       "      <td>38.954683</td>\n",
       "      <td>21.207851</td>\n",
       "      <td>20.596615</td>\n",
       "      <td>31.790128</td>\n",
       "      <td>31.808032</td>\n",
       "      <td>0.611236</td>\n",
       "      <td>0.017904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>NJOT_Aug_23_94</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>94</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.676950</td>\n",
       "      <td>39.141033</td>\n",
       "      <td>20.492487</td>\n",
       "      <td>18.477310</td>\n",
       "      <td>31.893909</td>\n",
       "      <td>31.978538</td>\n",
       "      <td>2.015177</td>\n",
       "      <td>0.084629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>NJOT_Aug_23_95</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>95</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.497300</td>\n",
       "      <td>39.165833</td>\n",
       "      <td>20.549352</td>\n",
       "      <td>16.286042</td>\n",
       "      <td>31.850125</td>\n",
       "      <td>32.115440</td>\n",
       "      <td>4.263310</td>\n",
       "      <td>0.265314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>NJOT_Aug_23_97</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>97</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.023817</td>\n",
       "      <td>39.357500</td>\n",
       "      <td>22.971803</td>\n",
       "      <td>14.291715</td>\n",
       "      <td>31.494135</td>\n",
       "      <td>32.288327</td>\n",
       "      <td>8.680087</td>\n",
       "      <td>0.794192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>NJOT_Aug_23_99</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>99</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.925150</td>\n",
       "      <td>39.493350</td>\n",
       "      <td>23.620753</td>\n",
       "      <td>14.631960</td>\n",
       "      <td>31.589262</td>\n",
       "      <td>32.555056</td>\n",
       "      <td>8.988793</td>\n",
       "      <td>0.965794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id project    date sampling_bout  gear sample_grp  station  \\\n",
       "0   NJOT_Feb_24_10    NJOT  2/1/24        Feb_24  edna      Trawl       10   \n",
       "1   NJOT_Feb_24_11    NJOT  2/1/24        Feb_24  edna      Trawl       11   \n",
       "2   NJOT_Feb_24_12    NJOT  2/1/24        Feb_24  edna      Trawl       12   \n",
       "3   NJOT_Feb_24_13    NJOT  2/1/24        Feb_24  edna      Trawl       13   \n",
       "4   NJOT_Feb_24_14    NJOT  2/1/24        Feb_24  edna      Trawl       14   \n",
       "..             ...     ...     ...           ...   ...        ...      ...   \n",
       "79  NJOT_Aug_23_93    NJOT  8/1/23        Aug_23  edna      Trawl       93   \n",
       "80  NJOT_Aug_23_94    NJOT  8/1/23        Aug_23  edna      Trawl       94   \n",
       "81  NJOT_Aug_23_95    NJOT  8/1/23        Aug_23  edna      Trawl       95   \n",
       "82  NJOT_Aug_23_97    NJOT  8/1/23        Aug_23  edna      Trawl       97   \n",
       "83  NJOT_Aug_23_99    NJOT  8/1/23        Aug_23  edna      Trawl       99   \n",
       "\n",
       "   location  replicate primers  ...  White_catfish  Atl_salmon  Longitude  \\\n",
       "0         B          1    bony  ...            0.0         0.0 -74.568000   \n",
       "1         B          1    bony  ...            0.0         0.0 -74.618000   \n",
       "2         B          1    bony  ...            0.0         0.0 -74.672000   \n",
       "3         B          1    bony  ...            0.0         0.0 -74.928000   \n",
       "4         B          1    bony  ...            0.0         0.0 -74.969000   \n",
       "..      ...        ...     ...  ...            ...         ...        ...   \n",
       "79        B          1    bony  ...            0.0         0.0 -74.828700   \n",
       "80        B          1    bony  ...            0.0         0.0 -74.676950   \n",
       "81        B          1    bony  ...            0.0         0.0 -74.497300   \n",
       "82        B          1    bony  ...            0.0         0.0 -74.023817   \n",
       "83        B          1    bony  ...            0.0         0.0 -73.925150   \n",
       "\n",
       "     Latitude  Surface_Temp  Bottom_Temp  Surface_Salinity  Bottom_Salinity  \\\n",
       "0   38.874000      5.956091     5.913677         30.449176        30.469612   \n",
       "1   38.724000      6.265040     6.349604         30.647220        30.878290   \n",
       "2   38.728000      6.141931     6.000855         30.286460        30.501550   \n",
       "3   38.905000      5.563858     5.591211         30.637451        30.595319   \n",
       "4   38.843000      5.451434     5.624359         29.023967        30.008847   \n",
       "..        ...           ...          ...               ...              ...   \n",
       "79  38.954683     21.207851    20.596615         31.790128        31.808032   \n",
       "80  39.141033     20.492487    18.477310         31.893909        31.978538   \n",
       "81  39.165833     20.549352    16.286042         31.850125        32.115440   \n",
       "82  39.357500     22.971803    14.291715         31.494135        32.288327   \n",
       "83  39.493350     23.620753    14.631960         31.589262        32.555056   \n",
       "\n",
       "    temp_strat  salt_strat  \n",
       "0     0.042414    0.020436  \n",
       "1     0.084564    0.231070  \n",
       "2     0.141076    0.215090  \n",
       "3     0.027353    0.042131  \n",
       "4     0.172925    0.984880  \n",
       "..         ...         ...  \n",
       "79    0.611236    0.017904  \n",
       "80    2.015177    0.084629  \n",
       "81    4.263310    0.265314  \n",
       "82    8.680087    0.794192  \n",
       "83    8.988793    0.965794  \n",
       "\n",
       "[84 rows x 93 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('allseasons.csv')\n",
    "df=df.drop(['Unnamed: 0'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Temperature, salinity, and stratification avg by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surface_Temp</th>\n",
       "      <th>Surface_Salinity</th>\n",
       "      <th>Bottom_Temp</th>\n",
       "      <th>Bottom_Salinity</th>\n",
       "      <th>temp_strat</th>\n",
       "      <th>salt_strat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.884859</td>\n",
       "      <td>28.815302</td>\n",
       "      <td>5.911421</td>\n",
       "      <td>30.052543</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>1.240503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.438544</td>\n",
       "      <td>2.181479</td>\n",
       "      <td>0.399104</td>\n",
       "      <td>0.876863</td>\n",
       "      <td>0.315077</td>\n",
       "      <td>1.656456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.708212</td>\n",
       "      <td>22.594429</td>\n",
       "      <td>5.016651</td>\n",
       "      <td>27.461980</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.000391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.581006</td>\n",
       "      <td>28.102602</td>\n",
       "      <td>5.609716</td>\n",
       "      <td>29.913880</td>\n",
       "      <td>0.082165</td>\n",
       "      <td>0.050269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.932552</td>\n",
       "      <td>29.741372</td>\n",
       "      <td>5.972974</td>\n",
       "      <td>30.263573</td>\n",
       "      <td>0.172925</td>\n",
       "      <td>0.231070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.126090</td>\n",
       "      <td>30.308458</td>\n",
       "      <td>6.139387</td>\n",
       "      <td>30.548435</td>\n",
       "      <td>0.311403</td>\n",
       "      <td>2.140432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.775392</td>\n",
       "      <td>30.839665</td>\n",
       "      <td>6.736478</td>\n",
       "      <td>30.945559</td>\n",
       "      <td>1.333313</td>\n",
       "      <td>4.880312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Surface_Temp  Surface_Salinity  Bottom_Temp  Bottom_Salinity  \\\n",
       "count     27.000000         27.000000    27.000000        27.000000   \n",
       "mean       5.884859         28.815302     5.911421        30.052543   \n",
       "std        0.438544          2.181479     0.399104         0.876863   \n",
       "min        4.708212         22.594429     5.016651        27.461980   \n",
       "25%        5.581006         28.102602     5.609716        29.913880   \n",
       "50%        5.932552         29.741372     5.972974        30.263573   \n",
       "75%        6.126090         30.308458     6.139387        30.548435   \n",
       "max        6.775392         30.839665     6.736478        30.945559   \n",
       "\n",
       "       temp_strat  salt_strat  \n",
       "count   27.000000   27.000000  \n",
       "mean     0.281400    1.240503  \n",
       "std      0.315077    1.656456  \n",
       "min      0.009290    0.000391  \n",
       "25%      0.082165    0.050269  \n",
       "50%      0.172925    0.231070  \n",
       "75%      0.311403    2.140432  \n",
       "max      1.333313    4.880312  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Surface_Temp', 'Surface_Salinity', 'Bottom_Temp', 'Bottom_Salinity', 'temp_strat', 'salt_strat']\n",
    "\n",
    "##change based off season\n",
    "sliced_df=df.loc[df['sampling_bout']=='Jun_23']\n",
    "# sliced_df=df.loc[df['sampling_bout']=='Aug_23']\n",
    "sliced_df=df.loc[df['sampling_bout']=='Feb_24']\n",
    "summary_stats = sliced_df[columns].describe()\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Surface Temp (Feb, June, Aug): 5.88, 16.62, 22.23  \n",
    "Average Surface Salinity: 28.815, 29.741, 30.581  \n",
    "Average Temperature Stratification: 0.281, 2.518, 4.739"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Dimensionality Reduction using PCA/tSNE on Dataset (*with Oceanographic Data*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>project</th>\n",
       "      <th>date</th>\n",
       "      <th>sampling_bout</th>\n",
       "      <th>gear</th>\n",
       "      <th>sample_grp</th>\n",
       "      <th>station</th>\n",
       "      <th>location</th>\n",
       "      <th>replicate</th>\n",
       "      <th>primers</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Surface_Temp</th>\n",
       "      <th>Bottom_Temp</th>\n",
       "      <th>Surface_Salinity</th>\n",
       "      <th>Bottom_Salinity</th>\n",
       "      <th>temp_strat</th>\n",
       "      <th>salt_strat</th>\n",
       "      <th>tSNE1</th>\n",
       "      <th>tSNE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NJOT_Feb_24_10</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.568000</td>\n",
       "      <td>38.874000</td>\n",
       "      <td>5.956091</td>\n",
       "      <td>5.913677</td>\n",
       "      <td>30.449176</td>\n",
       "      <td>30.469612</td>\n",
       "      <td>0.042414</td>\n",
       "      <td>0.020436</td>\n",
       "      <td>5.325099</td>\n",
       "      <td>-0.322492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NJOT_Feb_24_11</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>11</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.618000</td>\n",
       "      <td>38.724000</td>\n",
       "      <td>6.265040</td>\n",
       "      <td>6.349604</td>\n",
       "      <td>30.647220</td>\n",
       "      <td>30.878290</td>\n",
       "      <td>0.084564</td>\n",
       "      <td>0.231070</td>\n",
       "      <td>5.116933</td>\n",
       "      <td>-0.176540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJOT_Feb_24_12</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>12</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.672000</td>\n",
       "      <td>38.728000</td>\n",
       "      <td>6.141931</td>\n",
       "      <td>6.000855</td>\n",
       "      <td>30.286460</td>\n",
       "      <td>30.501550</td>\n",
       "      <td>0.141076</td>\n",
       "      <td>0.215090</td>\n",
       "      <td>5.425777</td>\n",
       "      <td>-0.230078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NJOT_Feb_24_13</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>13</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.928000</td>\n",
       "      <td>38.905000</td>\n",
       "      <td>5.563858</td>\n",
       "      <td>5.591211</td>\n",
       "      <td>30.637451</td>\n",
       "      <td>30.595319</td>\n",
       "      <td>0.027353</td>\n",
       "      <td>0.042131</td>\n",
       "      <td>5.230708</td>\n",
       "      <td>-0.631018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NJOT_Feb_24_14</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>14</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.969000</td>\n",
       "      <td>38.843000</td>\n",
       "      <td>5.451434</td>\n",
       "      <td>5.624359</td>\n",
       "      <td>29.023967</td>\n",
       "      <td>30.008847</td>\n",
       "      <td>0.172925</td>\n",
       "      <td>0.984880</td>\n",
       "      <td>6.392591</td>\n",
       "      <td>-0.569975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>NJOT_Aug_23_93</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>93</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.828700</td>\n",
       "      <td>38.954683</td>\n",
       "      <td>21.207851</td>\n",
       "      <td>20.596615</td>\n",
       "      <td>31.790128</td>\n",
       "      <td>31.808032</td>\n",
       "      <td>0.611236</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>-5.925606</td>\n",
       "      <td>0.441053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>NJOT_Aug_23_94</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>94</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.676950</td>\n",
       "      <td>39.141033</td>\n",
       "      <td>20.492487</td>\n",
       "      <td>18.477310</td>\n",
       "      <td>31.893909</td>\n",
       "      <td>31.978538</td>\n",
       "      <td>2.015177</td>\n",
       "      <td>0.084629</td>\n",
       "      <td>-5.259864</td>\n",
       "      <td>0.077095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>NJOT_Aug_23_95</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>95</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.497300</td>\n",
       "      <td>39.165833</td>\n",
       "      <td>20.549352</td>\n",
       "      <td>16.286042</td>\n",
       "      <td>31.850125</td>\n",
       "      <td>32.115440</td>\n",
       "      <td>4.263310</td>\n",
       "      <td>0.265314</td>\n",
       "      <td>-4.943742</td>\n",
       "      <td>-1.166944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>NJOT_Aug_23_97</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>97</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.023817</td>\n",
       "      <td>39.357500</td>\n",
       "      <td>22.971803</td>\n",
       "      <td>14.291715</td>\n",
       "      <td>31.494135</td>\n",
       "      <td>32.288327</td>\n",
       "      <td>8.680087</td>\n",
       "      <td>0.794192</td>\n",
       "      <td>-3.802218</td>\n",
       "      <td>-2.505854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>NJOT_Aug_23_99</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>99</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.925150</td>\n",
       "      <td>39.493350</td>\n",
       "      <td>23.620753</td>\n",
       "      <td>14.631960</td>\n",
       "      <td>31.589262</td>\n",
       "      <td>32.555056</td>\n",
       "      <td>8.988793</td>\n",
       "      <td>0.965794</td>\n",
       "      <td>-3.837243</td>\n",
       "      <td>-2.499078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id project    date sampling_bout  gear sample_grp  station  \\\n",
       "0   NJOT_Feb_24_10    NJOT  2/1/24        Feb_24  edna      Trawl       10   \n",
       "1   NJOT_Feb_24_11    NJOT  2/1/24        Feb_24  edna      Trawl       11   \n",
       "2   NJOT_Feb_24_12    NJOT  2/1/24        Feb_24  edna      Trawl       12   \n",
       "3   NJOT_Feb_24_13    NJOT  2/1/24        Feb_24  edna      Trawl       13   \n",
       "4   NJOT_Feb_24_14    NJOT  2/1/24        Feb_24  edna      Trawl       14   \n",
       "..             ...     ...     ...           ...   ...        ...      ...   \n",
       "79  NJOT_Aug_23_93    NJOT  8/1/23        Aug_23  edna      Trawl       93   \n",
       "80  NJOT_Aug_23_94    NJOT  8/1/23        Aug_23  edna      Trawl       94   \n",
       "81  NJOT_Aug_23_95    NJOT  8/1/23        Aug_23  edna      Trawl       95   \n",
       "82  NJOT_Aug_23_97    NJOT  8/1/23        Aug_23  edna      Trawl       97   \n",
       "83  NJOT_Aug_23_99    NJOT  8/1/23        Aug_23  edna      Trawl       99   \n",
       "\n",
       "   location  replicate primers  ...  Longitude   Latitude  Surface_Temp  \\\n",
       "0         B          1    bony  ... -74.568000  38.874000      5.956091   \n",
       "1         B          1    bony  ... -74.618000  38.724000      6.265040   \n",
       "2         B          1    bony  ... -74.672000  38.728000      6.141931   \n",
       "3         B          1    bony  ... -74.928000  38.905000      5.563858   \n",
       "4         B          1    bony  ... -74.969000  38.843000      5.451434   \n",
       "..      ...        ...     ...  ...        ...        ...           ...   \n",
       "79        B          1    bony  ... -74.828700  38.954683     21.207851   \n",
       "80        B          1    bony  ... -74.676950  39.141033     20.492487   \n",
       "81        B          1    bony  ... -74.497300  39.165833     20.549352   \n",
       "82        B          1    bony  ... -74.023817  39.357500     22.971803   \n",
       "83        B          1    bony  ... -73.925150  39.493350     23.620753   \n",
       "\n",
       "    Bottom_Temp  Surface_Salinity  Bottom_Salinity  temp_strat  salt_strat  \\\n",
       "0      5.913677         30.449176        30.469612    0.042414    0.020436   \n",
       "1      6.349604         30.647220        30.878290    0.084564    0.231070   \n",
       "2      6.000855         30.286460        30.501550    0.141076    0.215090   \n",
       "3      5.591211         30.637451        30.595319    0.027353    0.042131   \n",
       "4      5.624359         29.023967        30.008847    0.172925    0.984880   \n",
       "..          ...               ...              ...         ...         ...   \n",
       "79    20.596615         31.790128        31.808032    0.611236    0.017904   \n",
       "80    18.477310         31.893909        31.978538    2.015177    0.084629   \n",
       "81    16.286042         31.850125        32.115440    4.263310    0.265314   \n",
       "82    14.291715         31.494135        32.288327    8.680087    0.794192   \n",
       "83    14.631960         31.589262        32.555056    8.988793    0.965794   \n",
       "\n",
       "       tSNE1     tSNE2  \n",
       "0   5.325099 -0.322492  \n",
       "1   5.116933 -0.176540  \n",
       "2   5.425777 -0.230078  \n",
       "3   5.230708 -0.631018  \n",
       "4   6.392591 -0.569975  \n",
       "..       ...       ...  \n",
       "79 -5.925606  0.441053  \n",
       "80 -5.259864  0.077095  \n",
       "81 -4.943742 -1.166944  \n",
       "82 -3.802218 -2.505854  \n",
       "83 -3.837243 -2.499078  \n",
       "\n",
       "[84 rows x 95 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish_asvs = df.iloc[:, 11:]\n",
    "fish_asvs\n",
    "tsne_df = df\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=20, perplexity=20, learning_rate=5, n_iter=300) #test with diff perplexity\n",
    "tsne_result = tsne.fit_transform(fish_asvs)\n",
    "# Perform t-SNE\n",
    "\n",
    "# Add t-SNE results to the dataframe\n",
    "tsne_df['tSNE1'] = tsne_result[:, 0]\n",
    "tsne_df['tSNE2'] = tsne_result[:, 1]\n",
    "tsne_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='tSNE1', y='tSNE2', data=tsne_df, hue='date', s=100, palette='tab10')\n",
    "\n",
    "plt.title('tSNE of Fish ASVs colored by date')\n",
    "plt.xlabel('tSNE Component 1')\n",
    "plt.ylabel('tSNE Component 2')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifications for model: keep date, oceanographic variables.\n",
    "If date is a strong predictor, influence of migratory species may be too high! Remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>project</th>\n",
       "      <th>sampling_bout</th>\n",
       "      <th>gear</th>\n",
       "      <th>sample_grp</th>\n",
       "      <th>station</th>\n",
       "      <th>location</th>\n",
       "      <th>replicate</th>\n",
       "      <th>primers</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Surface_Temp</th>\n",
       "      <th>Bottom_Temp</th>\n",
       "      <th>Surface_Salinity</th>\n",
       "      <th>Bottom_Salinity</th>\n",
       "      <th>temp_strat</th>\n",
       "      <th>salt_strat</th>\n",
       "      <th>date</th>\n",
       "      <th>tSNE1</th>\n",
       "      <th>tSNE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NJOT_Feb_24_10</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>38.874000</td>\n",
       "      <td>5.956091</td>\n",
       "      <td>5.913677</td>\n",
       "      <td>30.449176</td>\n",
       "      <td>30.469612</td>\n",
       "      <td>0.042414</td>\n",
       "      <td>0.020436</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>5.325099</td>\n",
       "      <td>-0.322492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NJOT_Feb_24_11</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>11</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>38.724000</td>\n",
       "      <td>6.265040</td>\n",
       "      <td>6.349604</td>\n",
       "      <td>30.647220</td>\n",
       "      <td>30.878290</td>\n",
       "      <td>0.084564</td>\n",
       "      <td>0.231070</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>5.116933</td>\n",
       "      <td>-0.176540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJOT_Feb_24_12</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>12</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>38.728000</td>\n",
       "      <td>6.141931</td>\n",
       "      <td>6.000855</td>\n",
       "      <td>30.286460</td>\n",
       "      <td>30.501550</td>\n",
       "      <td>0.141076</td>\n",
       "      <td>0.215090</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>5.425777</td>\n",
       "      <td>-0.230078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NJOT_Feb_24_13</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>13</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>38.905000</td>\n",
       "      <td>5.563858</td>\n",
       "      <td>5.591211</td>\n",
       "      <td>30.637451</td>\n",
       "      <td>30.595319</td>\n",
       "      <td>0.027353</td>\n",
       "      <td>0.042131</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>5.230708</td>\n",
       "      <td>-0.631018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NJOT_Feb_24_14</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>Feb_24</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>14</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>38.843000</td>\n",
       "      <td>5.451434</td>\n",
       "      <td>5.624359</td>\n",
       "      <td>29.023967</td>\n",
       "      <td>30.008847</td>\n",
       "      <td>0.172925</td>\n",
       "      <td>0.984880</td>\n",
       "      <td>2/1/24</td>\n",
       "      <td>6.392591</td>\n",
       "      <td>-0.569975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>NJOT_Aug_23_93</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>93</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>38.954683</td>\n",
       "      <td>21.207851</td>\n",
       "      <td>20.596615</td>\n",
       "      <td>31.790128</td>\n",
       "      <td>31.808032</td>\n",
       "      <td>0.611236</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>-5.925606</td>\n",
       "      <td>0.441053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>NJOT_Aug_23_94</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>94</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>39.141033</td>\n",
       "      <td>20.492487</td>\n",
       "      <td>18.477310</td>\n",
       "      <td>31.893909</td>\n",
       "      <td>31.978538</td>\n",
       "      <td>2.015177</td>\n",
       "      <td>0.084629</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>-5.259864</td>\n",
       "      <td>0.077095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>NJOT_Aug_23_95</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>95</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>39.165833</td>\n",
       "      <td>20.549352</td>\n",
       "      <td>16.286042</td>\n",
       "      <td>31.850125</td>\n",
       "      <td>32.115440</td>\n",
       "      <td>4.263310</td>\n",
       "      <td>0.265314</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>-4.943742</td>\n",
       "      <td>-1.166944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>NJOT_Aug_23_97</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>97</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>39.357500</td>\n",
       "      <td>22.971803</td>\n",
       "      <td>14.291715</td>\n",
       "      <td>31.494135</td>\n",
       "      <td>32.288327</td>\n",
       "      <td>8.680087</td>\n",
       "      <td>0.794192</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>-3.802218</td>\n",
       "      <td>-2.505854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>NJOT_Aug_23_99</td>\n",
       "      <td>NJOT</td>\n",
       "      <td>Aug_23</td>\n",
       "      <td>edna</td>\n",
       "      <td>Trawl</td>\n",
       "      <td>99</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>bony</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>39.493350</td>\n",
       "      <td>23.620753</td>\n",
       "      <td>14.631960</td>\n",
       "      <td>31.589262</td>\n",
       "      <td>32.555056</td>\n",
       "      <td>8.988793</td>\n",
       "      <td>0.965794</td>\n",
       "      <td>8/1/23</td>\n",
       "      <td>-3.837243</td>\n",
       "      <td>-2.499078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id project sampling_bout  gear sample_grp  station location  \\\n",
       "0   NJOT_Feb_24_10    NJOT        Feb_24  edna      Trawl       10        B   \n",
       "1   NJOT_Feb_24_11    NJOT        Feb_24  edna      Trawl       11        B   \n",
       "2   NJOT_Feb_24_12    NJOT        Feb_24  edna      Trawl       12        B   \n",
       "3   NJOT_Feb_24_13    NJOT        Feb_24  edna      Trawl       13        B   \n",
       "4   NJOT_Feb_24_14    NJOT        Feb_24  edna      Trawl       14        B   \n",
       "..             ...     ...           ...   ...        ...      ...      ...   \n",
       "79  NJOT_Aug_23_93    NJOT        Aug_23  edna      Trawl       93        B   \n",
       "80  NJOT_Aug_23_94    NJOT        Aug_23  edna      Trawl       94        B   \n",
       "81  NJOT_Aug_23_95    NJOT        Aug_23  edna      Trawl       95        B   \n",
       "82  NJOT_Aug_23_97    NJOT        Aug_23  edna      Trawl       97        B   \n",
       "83  NJOT_Aug_23_99    NJOT        Aug_23  edna      Trawl       99        B   \n",
       "\n",
       "    replicate primers  category  ...   Latitude  Surface_Temp  Bottom_Temp  \\\n",
       "0           1    bony         1  ...  38.874000      5.956091     5.913677   \n",
       "1           1    bony         1  ...  38.724000      6.265040     6.349604   \n",
       "2           1    bony         1  ...  38.728000      6.141931     6.000855   \n",
       "3           1    bony         1  ...  38.905000      5.563858     5.591211   \n",
       "4           1    bony         1  ...  38.843000      5.451434     5.624359   \n",
       "..        ...     ...       ...  ...        ...           ...          ...   \n",
       "79          1    bony         1  ...  38.954683     21.207851    20.596615   \n",
       "80          1    bony         1  ...  39.141033     20.492487    18.477310   \n",
       "81          1    bony         1  ...  39.165833     20.549352    16.286042   \n",
       "82          1    bony         1  ...  39.357500     22.971803    14.291715   \n",
       "83          1    bony         1  ...  39.493350     23.620753    14.631960   \n",
       "\n",
       "    Surface_Salinity  Bottom_Salinity  temp_strat  salt_strat    date  \\\n",
       "0          30.449176        30.469612    0.042414    0.020436  2/1/24   \n",
       "1          30.647220        30.878290    0.084564    0.231070  2/1/24   \n",
       "2          30.286460        30.501550    0.141076    0.215090  2/1/24   \n",
       "3          30.637451        30.595319    0.027353    0.042131  2/1/24   \n",
       "4          29.023967        30.008847    0.172925    0.984880  2/1/24   \n",
       "..               ...              ...         ...         ...     ...   \n",
       "79         31.790128        31.808032    0.611236    0.017904  8/1/23   \n",
       "80         31.893909        31.978538    2.015177    0.084629  8/1/23   \n",
       "81         31.850125        32.115440    4.263310    0.265314  8/1/23   \n",
       "82         31.494135        32.288327    8.680087    0.794192  8/1/23   \n",
       "83         31.589262        32.555056    8.988793    0.965794  8/1/23   \n",
       "\n",
       "       tSNE1     tSNE2  \n",
       "0   5.325099 -0.322492  \n",
       "1   5.116933 -0.176540  \n",
       "2   5.425777 -0.230078  \n",
       "3   5.230708 -0.631018  \n",
       "4   6.392591 -0.569975  \n",
       "..       ...       ...  \n",
       "79 -5.925606  0.441053  \n",
       "80 -5.259864  0.077095  \n",
       "81 -4.943742 -1.166944  \n",
       "82 -3.802218 -2.505854  \n",
       "83 -3.837243 -2.499078  \n",
       "\n",
       "[84 rows x 95 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_to_move = df.pop(\"date\")\n",
    "# insert column with insert(location, column_name, column_value)\n",
    "\n",
    "df.insert(92, \"date\", column_to_move)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atl_croaker_(nibea98)</th>\n",
       "      <th>Bay_anchovy</th>\n",
       "      <th>Black_drum_or_Spot</th>\n",
       "      <th>Black_sea_bass</th>\n",
       "      <th>Brd_striped_anchovy</th>\n",
       "      <th>Little_tunny_or_skipjack_tuna</th>\n",
       "      <th>Nor_sea_robin</th>\n",
       "      <th>Scup</th>\n",
       "      <th>Smallmouth_flounder</th>\n",
       "      <th>Southern_kingfish(nibea95)</th>\n",
       "      <th>...</th>\n",
       "      <th>Atl_salmon</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Surface_Temp</th>\n",
       "      <th>Bottom_Temp</th>\n",
       "      <th>Surface_Salinity</th>\n",
       "      <th>Bottom_Salinity</th>\n",
       "      <th>temp_strat</th>\n",
       "      <th>salt_strat</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021454</td>\n",
       "      <td>0.040537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024768</td>\n",
       "      <td>0.006895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.568000</td>\n",
       "      <td>38.874000</td>\n",
       "      <td>5.956091</td>\n",
       "      <td>5.913677</td>\n",
       "      <td>30.449176</td>\n",
       "      <td>30.469612</td>\n",
       "      <td>0.042414</td>\n",
       "      <td>0.020436</td>\n",
       "      <td>2/1/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.009241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.618000</td>\n",
       "      <td>38.724000</td>\n",
       "      <td>6.265040</td>\n",
       "      <td>6.349604</td>\n",
       "      <td>30.647220</td>\n",
       "      <td>30.878290</td>\n",
       "      <td>0.084564</td>\n",
       "      <td>0.231070</td>\n",
       "      <td>2/1/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030301</td>\n",
       "      <td>0.011375</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064406</td>\n",
       "      <td>0.020961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.672000</td>\n",
       "      <td>38.728000</td>\n",
       "      <td>6.141931</td>\n",
       "      <td>6.000855</td>\n",
       "      <td>30.286460</td>\n",
       "      <td>30.501550</td>\n",
       "      <td>0.141076</td>\n",
       "      <td>0.215090</td>\n",
       "      <td>2/1/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.020035</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>0.015582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.928000</td>\n",
       "      <td>38.905000</td>\n",
       "      <td>5.563858</td>\n",
       "      <td>5.591211</td>\n",
       "      <td>30.637451</td>\n",
       "      <td>30.595319</td>\n",
       "      <td>0.027353</td>\n",
       "      <td>0.042131</td>\n",
       "      <td>2/1/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016257</td>\n",
       "      <td>0.040472</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037753</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.969000</td>\n",
       "      <td>38.843000</td>\n",
       "      <td>5.451434</td>\n",
       "      <td>5.624359</td>\n",
       "      <td>29.023967</td>\n",
       "      <td>30.008847</td>\n",
       "      <td>0.172925</td>\n",
       "      <td>0.984880</td>\n",
       "      <td>2/1/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.147357</td>\n",
       "      <td>0.033101</td>\n",
       "      <td>0.074028</td>\n",
       "      <td>0.028071</td>\n",
       "      <td>0.049606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.066560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.828700</td>\n",
       "      <td>38.954683</td>\n",
       "      <td>21.207851</td>\n",
       "      <td>20.596615</td>\n",
       "      <td>31.790128</td>\n",
       "      <td>31.808032</td>\n",
       "      <td>0.611236</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>8/1/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.020967</td>\n",
       "      <td>0.034878</td>\n",
       "      <td>0.161804</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.142219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053829</td>\n",
       "      <td>0.020391</td>\n",
       "      <td>0.016820</td>\n",
       "      <td>0.147087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.676950</td>\n",
       "      <td>39.141033</td>\n",
       "      <td>20.492487</td>\n",
       "      <td>18.477310</td>\n",
       "      <td>31.893909</td>\n",
       "      <td>31.978538</td>\n",
       "      <td>2.015177</td>\n",
       "      <td>0.084629</td>\n",
       "      <td>8/1/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.087133</td>\n",
       "      <td>0.044501</td>\n",
       "      <td>0.073490</td>\n",
       "      <td>0.046578</td>\n",
       "      <td>0.173540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082357</td>\n",
       "      <td>0.020870</td>\n",
       "      <td>0.024877</td>\n",
       "      <td>0.052247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.497300</td>\n",
       "      <td>39.165833</td>\n",
       "      <td>20.549352</td>\n",
       "      <td>16.286042</td>\n",
       "      <td>31.850125</td>\n",
       "      <td>32.115440</td>\n",
       "      <td>4.263310</td>\n",
       "      <td>0.265314</td>\n",
       "      <td>8/1/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.021997</td>\n",
       "      <td>0.065793</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>0.041255</td>\n",
       "      <td>0.137145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336827</td>\n",
       "      <td>0.030375</td>\n",
       "      <td>0.014215</td>\n",
       "      <td>0.066587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.023817</td>\n",
       "      <td>39.357500</td>\n",
       "      <td>22.971803</td>\n",
       "      <td>14.291715</td>\n",
       "      <td>31.494135</td>\n",
       "      <td>32.288327</td>\n",
       "      <td>8.680087</td>\n",
       "      <td>0.794192</td>\n",
       "      <td>8/1/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.034771</td>\n",
       "      <td>0.052803</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>0.033436</td>\n",
       "      <td>0.046080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520725</td>\n",
       "      <td>0.025644</td>\n",
       "      <td>0.021994</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.925150</td>\n",
       "      <td>39.493350</td>\n",
       "      <td>23.620753</td>\n",
       "      <td>14.631960</td>\n",
       "      <td>31.589262</td>\n",
       "      <td>32.555056</td>\n",
       "      <td>8.988793</td>\n",
       "      <td>0.965794</td>\n",
       "      <td>8/1/23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Atl_croaker_(nibea98)  Bay_anchovy  Black_drum_or_Spot  Black_sea_bass  \\\n",
       "0                0.000000     0.021454            0.040537        0.000000   \n",
       "1                0.000000     0.013388            0.009241        0.000000   \n",
       "2                0.030301     0.011375            0.013220        0.026649   \n",
       "3                0.002777     0.020035            0.002677        0.003510   \n",
       "4                0.016257     0.040472            0.004415        0.000487   \n",
       "..                    ...          ...                 ...             ...   \n",
       "79               0.147357     0.033101            0.074028        0.028071   \n",
       "80               0.020967     0.034878            0.161804        0.012557   \n",
       "81               0.087133     0.044501            0.073490        0.046578   \n",
       "82               0.021997     0.065793            0.030653        0.041255   \n",
       "83               0.034771     0.052803            0.019055        0.033436   \n",
       "\n",
       "    Brd_striped_anchovy  Little_tunny_or_skipjack_tuna  Nor_sea_robin  \\\n",
       "0              0.000000                            0.0       0.013350   \n",
       "1              0.000000                            0.0       0.028128   \n",
       "2              0.000000                            0.0       0.064406   \n",
       "3              0.000000                            0.0       0.000000   \n",
       "4              0.000000                            0.0       0.001678   \n",
       "..                  ...                            ...            ...   \n",
       "79             0.049606                            0.0       0.126987   \n",
       "80             0.142219                            0.0       0.053829   \n",
       "81             0.173540                            0.0       0.082357   \n",
       "82             0.137145                            0.0       0.336827   \n",
       "83             0.046080                            0.0       0.520725   \n",
       "\n",
       "        Scup  Smallmouth_flounder  Southern_kingfish(nibea95)  ...  \\\n",
       "0   0.000000             0.024768                    0.006895  ...   \n",
       "1   0.000000             0.054104                    0.000000  ...   \n",
       "2   0.020961             0.000000                    0.006125  ...   \n",
       "3   0.005064             0.015582                    0.000000  ...   \n",
       "4   0.000000             0.037753                    0.000421  ...   \n",
       "..       ...                  ...                         ...  ...   \n",
       "79  0.000000             0.006381                    0.066560  ...   \n",
       "80  0.020391             0.016820                    0.147087  ...   \n",
       "81  0.020870             0.024877                    0.052247  ...   \n",
       "82  0.030375             0.014215                    0.066587  ...   \n",
       "83  0.025644             0.021994                    0.053114  ...   \n",
       "\n",
       "    Atl_salmon  Longitude   Latitude  Surface_Temp  Bottom_Temp  \\\n",
       "0          0.0 -74.568000  38.874000      5.956091     5.913677   \n",
       "1          0.0 -74.618000  38.724000      6.265040     6.349604   \n",
       "2          0.0 -74.672000  38.728000      6.141931     6.000855   \n",
       "3          0.0 -74.928000  38.905000      5.563858     5.591211   \n",
       "4          0.0 -74.969000  38.843000      5.451434     5.624359   \n",
       "..         ...        ...        ...           ...          ...   \n",
       "79         0.0 -74.828700  38.954683     21.207851    20.596615   \n",
       "80         0.0 -74.676950  39.141033     20.492487    18.477310   \n",
       "81         0.0 -74.497300  39.165833     20.549352    16.286042   \n",
       "82         0.0 -74.023817  39.357500     22.971803    14.291715   \n",
       "83         0.0 -73.925150  39.493350     23.620753    14.631960   \n",
       "\n",
       "    Surface_Salinity  Bottom_Salinity  temp_strat  salt_strat    date  \n",
       "0          30.449176        30.469612    0.042414    0.020436  2/1/24  \n",
       "1          30.647220        30.878290    0.084564    0.231070  2/1/24  \n",
       "2          30.286460        30.501550    0.141076    0.215090  2/1/24  \n",
       "3          30.637451        30.595319    0.027353    0.042131  2/1/24  \n",
       "4          29.023967        30.008847    0.172925    0.984880  2/1/24  \n",
       "..               ...              ...         ...         ...     ...  \n",
       "79         31.790128        31.808032    0.611236    0.017904  8/1/23  \n",
       "80         31.893909        31.978538    2.015177    0.084629  8/1/23  \n",
       "81         31.850125        32.115440    4.263310    0.265314  8/1/23  \n",
       "82         31.494135        32.288327    8.680087    0.794192  8/1/23  \n",
       "83         31.589262        32.555056    8.988793    0.965794  8/1/23  \n",
       "\n",
       "[84 rows x 83 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Keep date - modify existing code\n",
    "## Plot feature importance\n",
    "ml_df = df.iloc[:,10:] # type: ignore\n",
    "ml_df = ml_df.drop(['tSNE1','tSNE2'],axis=1)\n",
    "ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atl_croaker_(nibea98)</th>\n",
       "      <th>Bay_anchovy</th>\n",
       "      <th>Black_drum_or_Spot</th>\n",
       "      <th>Black_sea_bass</th>\n",
       "      <th>Brd_striped_anchovy</th>\n",
       "      <th>Little_tunny_or_skipjack_tuna</th>\n",
       "      <th>Nor_sea_robin</th>\n",
       "      <th>Scup</th>\n",
       "      <th>Smallmouth_flounder</th>\n",
       "      <th>Southern_kingfish(nibea95)</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Surface_Temp</th>\n",
       "      <th>Bottom_Temp</th>\n",
       "      <th>Surface_Salinity</th>\n",
       "      <th>Bottom_Salinity</th>\n",
       "      <th>temp_strat</th>\n",
       "      <th>salt_strat</th>\n",
       "      <th>date</th>\n",
       "      <th>date_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021454</td>\n",
       "      <td>0.040537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024768</td>\n",
       "      <td>0.006895</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.568000</td>\n",
       "      <td>38.874000</td>\n",
       "      <td>5.956091</td>\n",
       "      <td>5.913677</td>\n",
       "      <td>30.449176</td>\n",
       "      <td>30.469612</td>\n",
       "      <td>0.042414</td>\n",
       "      <td>0.020436</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>19754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.009241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.618000</td>\n",
       "      <td>38.724000</td>\n",
       "      <td>6.265040</td>\n",
       "      <td>6.349604</td>\n",
       "      <td>30.647220</td>\n",
       "      <td>30.878290</td>\n",
       "      <td>0.084564</td>\n",
       "      <td>0.231070</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>19754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030301</td>\n",
       "      <td>0.011375</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064406</td>\n",
       "      <td>0.020961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006125</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.672000</td>\n",
       "      <td>38.728000</td>\n",
       "      <td>6.141931</td>\n",
       "      <td>6.000855</td>\n",
       "      <td>30.286460</td>\n",
       "      <td>30.501550</td>\n",
       "      <td>0.141076</td>\n",
       "      <td>0.215090</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>19754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.020035</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>0.015582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.928000</td>\n",
       "      <td>38.905000</td>\n",
       "      <td>5.563858</td>\n",
       "      <td>5.591211</td>\n",
       "      <td>30.637451</td>\n",
       "      <td>30.595319</td>\n",
       "      <td>0.027353</td>\n",
       "      <td>0.042131</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>19754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016257</td>\n",
       "      <td>0.040472</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037753</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.969000</td>\n",
       "      <td>38.843000</td>\n",
       "      <td>5.451434</td>\n",
       "      <td>5.624359</td>\n",
       "      <td>29.023967</td>\n",
       "      <td>30.008847</td>\n",
       "      <td>0.172925</td>\n",
       "      <td>0.984880</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>19754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.147357</td>\n",
       "      <td>0.033101</td>\n",
       "      <td>0.074028</td>\n",
       "      <td>0.028071</td>\n",
       "      <td>0.049606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.066560</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.828700</td>\n",
       "      <td>38.954683</td>\n",
       "      <td>21.207851</td>\n",
       "      <td>20.596615</td>\n",
       "      <td>31.790128</td>\n",
       "      <td>31.808032</td>\n",
       "      <td>0.611236</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>19570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.020967</td>\n",
       "      <td>0.034878</td>\n",
       "      <td>0.161804</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.142219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053829</td>\n",
       "      <td>0.020391</td>\n",
       "      <td>0.016820</td>\n",
       "      <td>0.147087</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.676950</td>\n",
       "      <td>39.141033</td>\n",
       "      <td>20.492487</td>\n",
       "      <td>18.477310</td>\n",
       "      <td>31.893909</td>\n",
       "      <td>31.978538</td>\n",
       "      <td>2.015177</td>\n",
       "      <td>0.084629</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>19570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.087133</td>\n",
       "      <td>0.044501</td>\n",
       "      <td>0.073490</td>\n",
       "      <td>0.046578</td>\n",
       "      <td>0.173540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082357</td>\n",
       "      <td>0.020870</td>\n",
       "      <td>0.024877</td>\n",
       "      <td>0.052247</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.497300</td>\n",
       "      <td>39.165833</td>\n",
       "      <td>20.549352</td>\n",
       "      <td>16.286042</td>\n",
       "      <td>31.850125</td>\n",
       "      <td>32.115440</td>\n",
       "      <td>4.263310</td>\n",
       "      <td>0.265314</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>19570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.021997</td>\n",
       "      <td>0.065793</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>0.041255</td>\n",
       "      <td>0.137145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336827</td>\n",
       "      <td>0.030375</td>\n",
       "      <td>0.014215</td>\n",
       "      <td>0.066587</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.023817</td>\n",
       "      <td>39.357500</td>\n",
       "      <td>22.971803</td>\n",
       "      <td>14.291715</td>\n",
       "      <td>31.494135</td>\n",
       "      <td>32.288327</td>\n",
       "      <td>8.680087</td>\n",
       "      <td>0.794192</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>19570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.034771</td>\n",
       "      <td>0.052803</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>0.033436</td>\n",
       "      <td>0.046080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520725</td>\n",
       "      <td>0.025644</td>\n",
       "      <td>0.021994</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.925150</td>\n",
       "      <td>39.493350</td>\n",
       "      <td>23.620753</td>\n",
       "      <td>14.631960</td>\n",
       "      <td>31.589262</td>\n",
       "      <td>32.555056</td>\n",
       "      <td>8.988793</td>\n",
       "      <td>0.965794</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>19570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Atl_croaker_(nibea98)  Bay_anchovy  Black_drum_or_Spot  Black_sea_bass  \\\n",
       "0                0.000000     0.021454            0.040537        0.000000   \n",
       "1                0.000000     0.013388            0.009241        0.000000   \n",
       "2                0.030301     0.011375            0.013220        0.026649   \n",
       "3                0.002777     0.020035            0.002677        0.003510   \n",
       "4                0.016257     0.040472            0.004415        0.000487   \n",
       "..                    ...          ...                 ...             ...   \n",
       "79               0.147357     0.033101            0.074028        0.028071   \n",
       "80               0.020967     0.034878            0.161804        0.012557   \n",
       "81               0.087133     0.044501            0.073490        0.046578   \n",
       "82               0.021997     0.065793            0.030653        0.041255   \n",
       "83               0.034771     0.052803            0.019055        0.033436   \n",
       "\n",
       "    Brd_striped_anchovy  Little_tunny_or_skipjack_tuna  Nor_sea_robin  \\\n",
       "0              0.000000                            0.0       0.013350   \n",
       "1              0.000000                            0.0       0.028128   \n",
       "2              0.000000                            0.0       0.064406   \n",
       "3              0.000000                            0.0       0.000000   \n",
       "4              0.000000                            0.0       0.001678   \n",
       "..                  ...                            ...            ...   \n",
       "79             0.049606                            0.0       0.126987   \n",
       "80             0.142219                            0.0       0.053829   \n",
       "81             0.173540                            0.0       0.082357   \n",
       "82             0.137145                            0.0       0.336827   \n",
       "83             0.046080                            0.0       0.520725   \n",
       "\n",
       "        Scup  Smallmouth_flounder  Southern_kingfish(nibea95)  ...  Longitude  \\\n",
       "0   0.000000             0.024768                    0.006895  ... -74.568000   \n",
       "1   0.000000             0.054104                    0.000000  ... -74.618000   \n",
       "2   0.020961             0.000000                    0.006125  ... -74.672000   \n",
       "3   0.005064             0.015582                    0.000000  ... -74.928000   \n",
       "4   0.000000             0.037753                    0.000421  ... -74.969000   \n",
       "..       ...                  ...                         ...  ...        ...   \n",
       "79  0.000000             0.006381                    0.066560  ... -74.828700   \n",
       "80  0.020391             0.016820                    0.147087  ... -74.676950   \n",
       "81  0.020870             0.024877                    0.052247  ... -74.497300   \n",
       "82  0.030375             0.014215                    0.066587  ... -74.023817   \n",
       "83  0.025644             0.021994                    0.053114  ... -73.925150   \n",
       "\n",
       "     Latitude  Surface_Temp  Bottom_Temp  Surface_Salinity  Bottom_Salinity  \\\n",
       "0   38.874000      5.956091     5.913677         30.449176        30.469612   \n",
       "1   38.724000      6.265040     6.349604         30.647220        30.878290   \n",
       "2   38.728000      6.141931     6.000855         30.286460        30.501550   \n",
       "3   38.905000      5.563858     5.591211         30.637451        30.595319   \n",
       "4   38.843000      5.451434     5.624359         29.023967        30.008847   \n",
       "..        ...           ...          ...               ...              ...   \n",
       "79  38.954683     21.207851    20.596615         31.790128        31.808032   \n",
       "80  39.141033     20.492487    18.477310         31.893909        31.978538   \n",
       "81  39.165833     20.549352    16.286042         31.850125        32.115440   \n",
       "82  39.357500     22.971803    14.291715         31.494135        32.288327   \n",
       "83  39.493350     23.620753    14.631960         31.589262        32.555056   \n",
       "\n",
       "    temp_strat  salt_strat       date  date_numeric  \n",
       "0     0.042414    0.020436 2024-02-01         19754  \n",
       "1     0.084564    0.231070 2024-02-01         19754  \n",
       "2     0.141076    0.215090 2024-02-01         19754  \n",
       "3     0.027353    0.042131 2024-02-01         19754  \n",
       "4     0.172925    0.984880 2024-02-01         19754  \n",
       "..         ...         ...        ...           ...  \n",
       "79    0.611236    0.017904 2023-08-01         19570  \n",
       "80    2.015177    0.084629 2023-08-01         19570  \n",
       "81    4.263310    0.265314 2023-08-01         19570  \n",
       "82    8.680087    0.794192 2023-08-01         19570  \n",
       "83    8.988793    0.965794 2023-08-01         19570  \n",
       "\n",
       "[84 rows x 84 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df['date'] = pd.to_datetime(ml_df['date'], format='%m/%d/%y')\n",
    "# Convert datetime to timestamp (e.g., number of days since a reference date)\n",
    "ml_df['date_numeric'] = (ml_df['date'] - pd.Timestamp('1970-01-01')) // pd.Timedelta('1D')\n",
    "ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Atl_croaker_(nibea98):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80         7\n",
      "           1       0.94      0.89      0.92        19\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.85      0.88      0.86        26\n",
      "weighted avg       0.89      0.88      0.89        26\n",
      "\n",
      "Classification report for Bay_anchovy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.92      1.00      0.96        24\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Black_drum_or_Spot:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.92      0.96      0.94        23\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.71      0.64      0.67        26\n",
      "weighted avg       0.87      0.88      0.87        26\n",
      "\n",
      "Classification report for Black_sea_bass:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.75      0.55         4\n",
      "           1       0.95      0.82      0.88        22\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.69      0.78      0.71        26\n",
      "weighted avg       0.87      0.81      0.83        26\n",
      "\n",
      "Classification report for Brd_striped_anchovy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        10\n",
      "           1       0.89      1.00      0.94        16\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.94      0.90      0.92        26\n",
      "weighted avg       0.93      0.92      0.92        26\n",
      "\n",
      "Classification report for Little_tunny_or_skipjack_tuna:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Nor_sea_robin:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.92      0.96      0.94        23\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.71      0.64      0.67        26\n",
      "weighted avg       0.87      0.88      0.87        26\n",
      "\n",
      "Classification report for Scup:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         6\n",
      "           1       0.82      0.90      0.86        20\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.66      0.62      0.63        26\n",
      "weighted avg       0.74      0.77      0.75        26\n",
      "\n",
      "Classification report for Smallmouth_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33         5\n",
      "           1       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.92      0.60      0.62        26\n",
      "weighted avg       0.87      0.85      0.80        26\n",
      "\n",
      "Classification report for Southern_kingfish(nibea95):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57         7\n",
      "           1       0.84      0.84      0.84        19\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.71      0.71      0.71        26\n",
      "weighted avg       0.77      0.77      0.77        26\n",
      "\n",
      "Classification report for Str_sea_robin:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.60      0.72        15\n",
      "           1       0.62      0.91      0.74        11\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.76      0.75      0.73        26\n",
      "weighted avg       0.78      0.73      0.73        26\n",
      "\n",
      "Classification report for Summ_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.96      1.00      0.98        25\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Summ_flounder99a:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75        15\n",
      "           1       0.67      0.55      0.60        11\n",
      "\n",
      "    accuracy                           0.69        26\n",
      "   macro avg       0.69      0.67      0.68        26\n",
      "weighted avg       0.69      0.69      0.69        26\n",
      "\n",
      "Classification report for Weakfish_Cyn:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         3\n",
      "           1       1.00      0.87      0.93        23\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.75      0.93      0.80        26\n",
      "weighted avg       0.94      0.88      0.90        26\n",
      "\n",
      "Classification report for Windowpane_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Am_butterfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.96      1.00      0.98        25\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Atl_chub_mackerel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Frigate_or_bullet_tuna:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Giant_trevally99:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        24\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.75      0.96      0.81        26\n",
      "weighted avg       0.96      0.92      0.93        26\n",
      "\n",
      "Classification report for Hogchoker_trinectes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81        18\n",
      "           1       0.57      0.50      0.53         8\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.68      0.67      0.67        26\n",
      "weighted avg       0.72      0.73      0.73        26\n",
      "\n",
      "Classification report for Nor_kingfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71         7\n",
      "           1       0.89      0.89      0.89        19\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.80      0.80      0.80        26\n",
      "weighted avg       0.85      0.85      0.85        26\n",
      "\n",
      "Classification report for Red_White_or_Spotted_hake:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Spanish_mackerel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Tautog:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.77      0.67        13\n",
      "           1       0.67      0.46      0.55        13\n",
      "\n",
      "    accuracy                           0.62        26\n",
      "   macro avg       0.63      0.62      0.61        26\n",
      "weighted avg       0.63      0.62      0.61        26\n",
      "\n",
      "Classification report for Thread_herring:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88        19\n",
      "           1       0.75      0.43      0.55         7\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.78      0.69      0.71        26\n",
      "weighted avg       0.80      0.81      0.79        26\n",
      "\n",
      "Classification report for Atl_menhaden_LS16_or_river_herrings:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.96      0.88      0.92        25\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.48      0.44      0.46        26\n",
      "weighted avg       0.92      0.85      0.88        26\n",
      "\n",
      "Classification report for Cobia:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Cunner:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Am_conger:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        25\n",
      "           1       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.62      0.94      0.67        26\n",
      "weighted avg       0.97      0.88      0.92        26\n",
      "\n",
      "Classification report for Atl_or_nor_sand_lance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.93      0.76        14\n",
      "           1       0.83      0.42      0.56        12\n",
      "\n",
      "    accuracy                           0.69        26\n",
      "   macro avg       0.74      0.67      0.66        26\n",
      "weighted avg       0.73      0.69      0.67        26\n",
      "\n",
      "Classification report for Bluefish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71         9\n",
      "           1       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.79      0.77      0.78        26\n",
      "weighted avg       0.80      0.81      0.80        26\n",
      "\n",
      "Classification report for Silver_anchovy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        23\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.96      0.67      0.73        26\n",
      "weighted avg       0.93      0.92      0.91        26\n",
      "\n",
      "Classification report for Seaboard_goby:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        18\n",
      "           1       1.00      0.12      0.22         8\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.86      0.56      0.53        26\n",
      "weighted avg       0.81      0.73      0.65        26\n",
      "\n",
      "Classification report for Nor_puffer:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89        22\n",
      "           1       0.33      0.25      0.29         4\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.60      0.58      0.59        26\n",
      "weighted avg       0.79      0.81      0.80        26\n",
      "\n",
      "Classification report for Silver_perch(nibea93):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.91      0.67        11\n",
      "           1       0.86      0.40      0.55        15\n",
      "\n",
      "    accuracy                           0.62        26\n",
      "   macro avg       0.69      0.65      0.61        26\n",
      "weighted avg       0.72      0.62      0.60        26\n",
      "\n",
      "Classification report for Sturgeon:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        16\n",
      "           1       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.76      0.76      0.76        26\n",
      "weighted avg       0.77      0.77      0.77        26\n",
      "\n",
      "Classification report for Crested_blenny_refseq_not_full_length:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Str_burrfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Dwarf_goatfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Fourspot_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        20\n",
      "           1       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.78      0.78      0.78        26\n",
      "weighted avg       0.85      0.85      0.85        26\n",
      "\n",
      "Classification report for Nor_sennet95:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        21\n",
      "           1       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.92      0.60      0.62        26\n",
      "weighted avg       0.87      0.85      0.80        26\n",
      "\n",
      "Classification report for Tuna_sp:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Atl_moonfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        24\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.73      0.73      0.73        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n",
      "Classification report for Atl_silverside:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        16\n",
      "           1       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.89      0.87      0.88        26\n",
      "weighted avg       0.88      0.88      0.88        26\n",
      "\n",
      "Classification report for Gulf_stream_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87        21\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.40      0.48      0.43        26\n",
      "weighted avg       0.65      0.77      0.70        26\n",
      "\n",
      "Classification report for Str_cusk_eel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        23\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.96      0.67      0.73        26\n",
      "weighted avg       0.93      0.92      0.91        26\n",
      "\n",
      "Classification report for Nor_stargazer:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Grey_triggerfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Nor_pipefish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        22\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.42      0.50      0.46        26\n",
      "weighted avg       0.72      0.85      0.78        26\n",
      "\n",
      "Classification report for Planehead_filefish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Rough_scad:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        20\n",
      "           1       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.92      0.67      0.70        26\n",
      "weighted avg       0.87      0.85      0.81        26\n",
      "\n",
      "Classification report for Str_killifish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Mummichog:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.48      0.48      0.48        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n",
      "Classification report for Rough_silverside94:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Sheepshead_minnow:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Str_bass:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86        18\n",
      "           1       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.78      0.76      0.77        26\n",
      "weighted avg       0.80      0.81      0.80        26\n",
      "\n",
      "Classification report for White_mullet:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Am_eel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.48      0.44      0.46        26\n",
      "weighted avg       0.92      0.85      0.88        26\n",
      "\n",
      "Classification report for Red_eye_round_herring:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Inshore_lizardfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Atl_mackerel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Flathead_grey_mullet:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        22\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.42      0.50      0.46        26\n",
      "weighted avg       0.72      0.85      0.78        26\n",
      "\n",
      "Classification report for Silver_hake:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.71        17\n",
      "           1       0.50      0.67      0.57         9\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.64      0.66      0.64        26\n",
      "weighted avg       0.69      0.65      0.66        26\n",
      "\n",
      "Classification report for Winter_or_Yellowtail_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        20\n",
      "           1       0.50      0.33      0.40         6\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.66      0.62      0.63        26\n",
      "weighted avg       0.74      0.77      0.75        26\n",
      "\n",
      "Classification report for Atl_herring:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        23\n",
      "           1       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.80      0.96      0.85        26\n",
      "weighted avg       0.95      0.92      0.93        26\n",
      "\n",
      "Classification report for Atl_cod:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Am_gizzard_shad:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Fourspine_stickleback:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Catfish_sp:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for White_perch:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        25\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Whitefish_Cor:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Pac_sand_lance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for White_catfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Atl_salmon:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8892931392931392"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "## MULTI OUTPUT CLASSIFIER\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# features = ml_df[['Surface_Temp','Bottom_Temp','Surface_Salinity','Bottom_Salinity','temp_strat','salt_strat']]\n",
    "\n",
    "## temp only \n",
    "# features = ml_df[['Surface_Temp']]\n",
    "## salt only\n",
    "features = ml_df[['Surface_Salinity','Bottom_Salinity','salt_strat', 'Surface_Temp','Bottom_Temp','temp_strat','date_numeric']]\n",
    "\n",
    "labels = ml_df.loc[:,'Atl_croaker_(nibea98)':'Atl_salmon'].applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the multi-output Random Forest classifier\n",
    "rf_classifier = MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "for i, species in enumerate(labels.columns):\n",
    "    accuracy = accuracy_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    # precision = precision_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    # recall = recall_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    # f1 = f1_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Classification report for {species}:\\n\", classification_report(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    # print(f\"Accuracy for {species}: {accuracy}\")\n",
    "\n",
    "# Calculate overall average accuracy across all species\n",
    "average_accuracy = np.mean(accuracies)\n",
    "average_accuracy\n",
    "\n",
    "# # Evaluate the model\n",
    "# for i, species in enumerate(labels.columns):\n",
    "#     print(f\"Classification report for {species}:\\n\", classification_report(y_test.iloc[:, i], y_pred[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot\n",
    "feature_importance_df = pd.DataFrame() # type: ignore\n",
    "for i, species in enumerate(labels.columns):\n",
    "    importances = rf_classifier.estimators_[i].feature_importances_\n",
    "    feature_importance_df[species] = importances\n",
    "\n",
    "# Calculate mean feature importance across all species\n",
    "feature_importance_df['mean_importance'] = feature_importance_df.mean(axis=1)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(features.columns, feature_importance_df['mean_importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Mean Feature Importance Across All Species')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ran without rare species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atl_croaker_(nibea98)</th>\n",
       "      <th>Bay_anchovy</th>\n",
       "      <th>Black_drum_or_Spot</th>\n",
       "      <th>Black_sea_bass</th>\n",
       "      <th>Brd_striped_anchovy</th>\n",
       "      <th>Nor_sea_robin</th>\n",
       "      <th>Scup</th>\n",
       "      <th>Smallmouth_flounder</th>\n",
       "      <th>Southern_kingfish(nibea95)</th>\n",
       "      <th>Str_sea_robin</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Surface_Temp</th>\n",
       "      <th>Bottom_Temp</th>\n",
       "      <th>Surface_Salinity</th>\n",
       "      <th>Bottom_Salinity</th>\n",
       "      <th>temp_strat</th>\n",
       "      <th>salt_strat</th>\n",
       "      <th>date</th>\n",
       "      <th>date_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021454</td>\n",
       "      <td>0.040537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024768</td>\n",
       "      <td>0.006895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.568000</td>\n",
       "      <td>38.874000</td>\n",
       "      <td>5.956091</td>\n",
       "      <td>5.913677</td>\n",
       "      <td>30.449176</td>\n",
       "      <td>30.469612</td>\n",
       "      <td>0.042414</td>\n",
       "      <td>0.020436</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>19754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.009241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.618000</td>\n",
       "      <td>38.724000</td>\n",
       "      <td>6.265040</td>\n",
       "      <td>6.349604</td>\n",
       "      <td>30.647220</td>\n",
       "      <td>30.878290</td>\n",
       "      <td>0.084564</td>\n",
       "      <td>0.231070</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>19754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030301</td>\n",
       "      <td>0.011375</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064406</td>\n",
       "      <td>0.020961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.672000</td>\n",
       "      <td>38.728000</td>\n",
       "      <td>6.141931</td>\n",
       "      <td>6.000855</td>\n",
       "      <td>30.286460</td>\n",
       "      <td>30.501550</td>\n",
       "      <td>0.141076</td>\n",
       "      <td>0.215090</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>19754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.020035</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>0.015582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.928000</td>\n",
       "      <td>38.905000</td>\n",
       "      <td>5.563858</td>\n",
       "      <td>5.591211</td>\n",
       "      <td>30.637451</td>\n",
       "      <td>30.595319</td>\n",
       "      <td>0.027353</td>\n",
       "      <td>0.042131</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>19754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016257</td>\n",
       "      <td>0.040472</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037753</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.969000</td>\n",
       "      <td>38.843000</td>\n",
       "      <td>5.451434</td>\n",
       "      <td>5.624359</td>\n",
       "      <td>29.023967</td>\n",
       "      <td>30.008847</td>\n",
       "      <td>0.172925</td>\n",
       "      <td>0.984880</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>19754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.147357</td>\n",
       "      <td>0.033101</td>\n",
       "      <td>0.074028</td>\n",
       "      <td>0.028071</td>\n",
       "      <td>0.049606</td>\n",
       "      <td>0.126987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.066560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.828700</td>\n",
       "      <td>38.954683</td>\n",
       "      <td>21.207851</td>\n",
       "      <td>20.596615</td>\n",
       "      <td>31.790128</td>\n",
       "      <td>31.808032</td>\n",
       "      <td>0.611236</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>19570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.020967</td>\n",
       "      <td>0.034878</td>\n",
       "      <td>0.161804</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.142219</td>\n",
       "      <td>0.053829</td>\n",
       "      <td>0.020391</td>\n",
       "      <td>0.016820</td>\n",
       "      <td>0.147087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.676950</td>\n",
       "      <td>39.141033</td>\n",
       "      <td>20.492487</td>\n",
       "      <td>18.477310</td>\n",
       "      <td>31.893909</td>\n",
       "      <td>31.978538</td>\n",
       "      <td>2.015177</td>\n",
       "      <td>0.084629</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>19570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.087133</td>\n",
       "      <td>0.044501</td>\n",
       "      <td>0.073490</td>\n",
       "      <td>0.046578</td>\n",
       "      <td>0.173540</td>\n",
       "      <td>0.082357</td>\n",
       "      <td>0.020870</td>\n",
       "      <td>0.024877</td>\n",
       "      <td>0.052247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.497300</td>\n",
       "      <td>39.165833</td>\n",
       "      <td>20.549352</td>\n",
       "      <td>16.286042</td>\n",
       "      <td>31.850125</td>\n",
       "      <td>32.115440</td>\n",
       "      <td>4.263310</td>\n",
       "      <td>0.265314</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>19570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.021997</td>\n",
       "      <td>0.065793</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>0.041255</td>\n",
       "      <td>0.137145</td>\n",
       "      <td>0.336827</td>\n",
       "      <td>0.030375</td>\n",
       "      <td>0.014215</td>\n",
       "      <td>0.066587</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.023817</td>\n",
       "      <td>39.357500</td>\n",
       "      <td>22.971803</td>\n",
       "      <td>14.291715</td>\n",
       "      <td>31.494135</td>\n",
       "      <td>32.288327</td>\n",
       "      <td>8.680087</td>\n",
       "      <td>0.794192</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>19570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.034771</td>\n",
       "      <td>0.052803</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>0.033436</td>\n",
       "      <td>0.046080</td>\n",
       "      <td>0.520725</td>\n",
       "      <td>0.025644</td>\n",
       "      <td>0.021994</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.925150</td>\n",
       "      <td>39.493350</td>\n",
       "      <td>23.620753</td>\n",
       "      <td>14.631960</td>\n",
       "      <td>31.589262</td>\n",
       "      <td>32.555056</td>\n",
       "      <td>8.988793</td>\n",
       "      <td>0.965794</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>19570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Atl_croaker_(nibea98)  Bay_anchovy  Black_drum_or_Spot  Black_sea_bass  \\\n",
       "0                0.000000     0.021454            0.040537        0.000000   \n",
       "1                0.000000     0.013388            0.009241        0.000000   \n",
       "2                0.030301     0.011375            0.013220        0.026649   \n",
       "3                0.002777     0.020035            0.002677        0.003510   \n",
       "4                0.016257     0.040472            0.004415        0.000487   \n",
       "..                    ...          ...                 ...             ...   \n",
       "79               0.147357     0.033101            0.074028        0.028071   \n",
       "80               0.020967     0.034878            0.161804        0.012557   \n",
       "81               0.087133     0.044501            0.073490        0.046578   \n",
       "82               0.021997     0.065793            0.030653        0.041255   \n",
       "83               0.034771     0.052803            0.019055        0.033436   \n",
       "\n",
       "    Brd_striped_anchovy  Nor_sea_robin      Scup  Smallmouth_flounder  \\\n",
       "0              0.000000       0.013350  0.000000             0.024768   \n",
       "1              0.000000       0.028128  0.000000             0.054104   \n",
       "2              0.000000       0.064406  0.020961             0.000000   \n",
       "3              0.000000       0.000000  0.005064             0.015582   \n",
       "4              0.000000       0.001678  0.000000             0.037753   \n",
       "..                  ...            ...       ...                  ...   \n",
       "79             0.049606       0.126987  0.000000             0.006381   \n",
       "80             0.142219       0.053829  0.020391             0.016820   \n",
       "81             0.173540       0.082357  0.020870             0.024877   \n",
       "82             0.137145       0.336827  0.030375             0.014215   \n",
       "83             0.046080       0.520725  0.025644             0.021994   \n",
       "\n",
       "    Southern_kingfish(nibea95)  Str_sea_robin  ...  Longitude   Latitude  \\\n",
       "0                     0.006895       0.000000  ... -74.568000  38.874000   \n",
       "1                     0.000000       0.000000  ... -74.618000  38.724000   \n",
       "2                     0.006125       0.000000  ... -74.672000  38.728000   \n",
       "3                     0.000000       0.000000  ... -74.928000  38.905000   \n",
       "4                     0.000421       0.000000  ... -74.969000  38.843000   \n",
       "..                         ...            ...  ...        ...        ...   \n",
       "79                    0.066560       0.000000  ... -74.828700  38.954683   \n",
       "80                    0.147087       0.000000  ... -74.676950  39.141033   \n",
       "81                    0.052247       0.000000  ... -74.497300  39.165833   \n",
       "82                    0.066587       0.005122  ... -74.023817  39.357500   \n",
       "83                    0.053114       0.000000  ... -73.925150  39.493350   \n",
       "\n",
       "    Surface_Temp  Bottom_Temp  Surface_Salinity  Bottom_Salinity  temp_strat  \\\n",
       "0       5.956091     5.913677         30.449176        30.469612    0.042414   \n",
       "1       6.265040     6.349604         30.647220        30.878290    0.084564   \n",
       "2       6.141931     6.000855         30.286460        30.501550    0.141076   \n",
       "3       5.563858     5.591211         30.637451        30.595319    0.027353   \n",
       "4       5.451434     5.624359         29.023967        30.008847    0.172925   \n",
       "..           ...          ...               ...              ...         ...   \n",
       "79     21.207851    20.596615         31.790128        31.808032    0.611236   \n",
       "80     20.492487    18.477310         31.893909        31.978538    2.015177   \n",
       "81     20.549352    16.286042         31.850125        32.115440    4.263310   \n",
       "82     22.971803    14.291715         31.494135        32.288327    8.680087   \n",
       "83     23.620753    14.631960         31.589262        32.555056    8.988793   \n",
       "\n",
       "    salt_strat       date  date_numeric  \n",
       "0     0.020436 2024-02-01         19754  \n",
       "1     0.231070 2024-02-01         19754  \n",
       "2     0.215090 2024-02-01         19754  \n",
       "3     0.042131 2024-02-01         19754  \n",
       "4     0.984880 2024-02-01         19754  \n",
       "..         ...        ...           ...  \n",
       "79    0.017904 2023-08-01         19570  \n",
       "80    0.084629 2023-08-01         19570  \n",
       "81    0.265314 2023-08-01         19570  \n",
       "82    0.794192 2023-08-01         19570  \n",
       "83    0.965794 2023-08-01         19570  \n",
       "\n",
       "[84 rows x 42 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = len(ml_df) * 0.2\n",
    "\n",
    "# Count the non-zero occurrences of each species\n",
    "species_columns = ml_df.columns[:-10]  # Adjust the slice to exclude non-species columns if needed\n",
    "species_counts = (ml_df[species_columns] > 0).sum()\n",
    "filtered_species = species_counts[species_counts >= threshold].index\n",
    "filtered_df = ml_df[filtered_species]\n",
    "non_species_columns = ml_df.columns[-10:]  # Adjust this if the non-species columns are at the end\n",
    "filtered_df = pd.concat([filtered_df, ml_df[non_species_columns]], axis=1)\n",
    "filtered_df = filtered_df.dropna()\n",
    "\n",
    "filtered_df\n",
    "filtered_ml_df = filtered_df\n",
    "# filtered_ml_df.to_csv('test')\n",
    "filtered_ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Atl_croaker_(nibea98):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80         7\n",
      "           1       0.94      0.89      0.92        19\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.85      0.88      0.86        26\n",
      "weighted avg       0.89      0.88      0.89        26\n",
      "\n",
      "Classification report for Bay_anchovy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.92      1.00      0.96        24\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Black_drum_or_Spot:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.92      1.00      0.96        23\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.96      0.67      0.73        26\n",
      "weighted avg       0.93      0.92      0.91        26\n",
      "\n",
      "Classification report for Black_sea_bass:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.75      0.60         4\n",
      "           1       0.95      0.86      0.90        22\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.72      0.81      0.75        26\n",
      "weighted avg       0.88      0.85      0.86        26\n",
      "\n",
      "Classification report for Brd_striped_anchovy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        10\n",
      "           1       0.89      1.00      0.94        16\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.94      0.90      0.92        26\n",
      "weighted avg       0.93      0.92      0.92        26\n",
      "\n",
      "Classification report for Little_tunny_or_skipjack_tuna:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Nor_sea_robin:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.92      0.96      0.94        23\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.71      0.64      0.67        26\n",
      "weighted avg       0.87      0.88      0.87        26\n",
      "\n",
      "Classification report for Scup:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         6\n",
      "           1       0.82      0.90      0.86        20\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.66      0.62      0.63        26\n",
      "weighted avg       0.74      0.77      0.75        26\n",
      "\n",
      "Classification report for Smallmouth_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.81      1.00      0.89        21\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.40      0.50      0.45        26\n",
      "weighted avg       0.65      0.81      0.72        26\n",
      "\n",
      "Classification report for Southern_kingfish(nibea95):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.29      0.36         7\n",
      "           1       0.77      0.89      0.83        19\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.64      0.59      0.60        26\n",
      "weighted avg       0.70      0.73      0.70        26\n",
      "\n",
      "Classification report for Str_sea_robin:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.60      0.72        15\n",
      "           1       0.62      0.91      0.74        11\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.76      0.75      0.73        26\n",
      "weighted avg       0.78      0.73      0.73        26\n",
      "\n",
      "Classification report for Summ_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.96      1.00      0.98        25\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Summ_flounder99a:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75        15\n",
      "           1       0.67      0.55      0.60        11\n",
      "\n",
      "    accuracy                           0.69        26\n",
      "   macro avg       0.69      0.67      0.68        26\n",
      "weighted avg       0.69      0.69      0.69        26\n",
      "\n",
      "Classification report for Weakfish_Cyn:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.67      0.50         3\n",
      "           1       0.95      0.87      0.91        23\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.68      0.77      0.70        26\n",
      "weighted avg       0.89      0.85      0.86        26\n",
      "\n",
      "Classification report for Windowpane_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Am_butterfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.96      1.00      0.98        25\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Atl_chub_mackerel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Frigate_or_bullet_tuna:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Giant_trevally99:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        24\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.75      0.96      0.81        26\n",
      "weighted avg       0.96      0.92      0.93        26\n",
      "\n",
      "Classification report for Hogchoker_trinectes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78        18\n",
      "           1       0.50      0.50      0.50         8\n",
      "\n",
      "    accuracy                           0.69        26\n",
      "   macro avg       0.64      0.64      0.64        26\n",
      "weighted avg       0.69      0.69      0.69        26\n",
      "\n",
      "Classification report for Nor_kingfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71         7\n",
      "           1       0.89      0.89      0.89        19\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.80      0.80      0.80        26\n",
      "weighted avg       0.85      0.85      0.85        26\n",
      "\n",
      "Classification report for Red_White_or_Spotted_hake:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Spanish_mackerel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Tautog:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.69      0.64        13\n",
      "           1       0.64      0.54      0.58        13\n",
      "\n",
      "    accuracy                           0.62        26\n",
      "   macro avg       0.62      0.62      0.61        26\n",
      "weighted avg       0.62      0.62      0.61        26\n",
      "\n",
      "Classification report for Thread_herring:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90        19\n",
      "           1       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.83      0.76      0.78        26\n",
      "weighted avg       0.84      0.85      0.84        26\n",
      "\n",
      "Classification report for Atl_menhaden_LS16_or_river_herrings:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.96      0.92      0.94        25\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.48      0.46      0.47        26\n",
      "weighted avg       0.92      0.88      0.90        26\n",
      "\n",
      "Classification report for Cobia:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Cunner:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Am_conger:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91        25\n",
      "           1       0.20      1.00      0.33         1\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.60      0.92      0.62        26\n",
      "weighted avg       0.97      0.85      0.89        26\n",
      "\n",
      "Classification report for Atl_or_nor_sand_lance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71        14\n",
      "           1       0.67      0.33      0.44        12\n",
      "\n",
      "    accuracy                           0.62        26\n",
      "   macro avg       0.63      0.60      0.58        26\n",
      "weighted avg       0.63      0.62      0.59        26\n",
      "\n",
      "Classification report for Bluefish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71         9\n",
      "           1       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.79      0.77      0.78        26\n",
      "weighted avg       0.80      0.81      0.80        26\n",
      "\n",
      "Classification report for Silver_anchovy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        23\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.96      0.67      0.73        26\n",
      "weighted avg       0.93      0.92      0.91        26\n",
      "\n",
      "Classification report for Seaboard_goby:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        18\n",
      "           1       1.00      0.12      0.22         8\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.86      0.56      0.53        26\n",
      "weighted avg       0.81      0.73      0.65        26\n",
      "\n",
      "Classification report for Nor_puffer:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89        22\n",
      "           1       0.33      0.25      0.29         4\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.60      0.58      0.59        26\n",
      "weighted avg       0.79      0.81      0.80        26\n",
      "\n",
      "Classification report for Silver_perch(nibea93):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.91      0.67        11\n",
      "           1       0.86      0.40      0.55        15\n",
      "\n",
      "    accuracy                           0.62        26\n",
      "   macro avg       0.69      0.65      0.61        26\n",
      "weighted avg       0.72      0.62      0.60        26\n",
      "\n",
      "Classification report for Sturgeon:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79        16\n",
      "           1       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.72      0.71      0.71        26\n",
      "weighted avg       0.73      0.73      0.73        26\n",
      "\n",
      "Classification report for Crested_blenny_refseq_not_full_length:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Str_burrfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Dwarf_goatfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Fourspot_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        20\n",
      "           1       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.78      0.78      0.78        26\n",
      "weighted avg       0.85      0.85      0.85        26\n",
      "\n",
      "Classification report for Nor_sennet95:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        21\n",
      "           1       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.92      0.60      0.62        26\n",
      "weighted avg       0.87      0.85      0.80        26\n",
      "\n",
      "Classification report for Tuna_sp:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Atl_moonfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        24\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.73      0.73      0.73        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n",
      "Classification report for Atl_silverside:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        16\n",
      "           1       0.80      0.80      0.80        10\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.84      0.84      0.84        26\n",
      "weighted avg       0.85      0.85      0.85        26\n",
      "\n",
      "Classification report for Gulf_stream_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87        21\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.40      0.48      0.43        26\n",
      "weighted avg       0.65      0.77      0.70        26\n",
      "\n",
      "Classification report for Str_cusk_eel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        23\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.96      0.67      0.73        26\n",
      "weighted avg       0.93      0.92      0.91        26\n",
      "\n",
      "Classification report for Nor_stargazer:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Grey_triggerfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Nor_pipefish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        22\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.42      0.50      0.46        26\n",
      "weighted avg       0.72      0.85      0.78        26\n",
      "\n",
      "Classification report for Planehead_filefish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Rough_scad:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        20\n",
      "           1       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.90      0.58      0.59        26\n",
      "weighted avg       0.85      0.81      0.75        26\n",
      "\n",
      "Classification report for Str_killifish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Mummichog:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.48      0.48      0.48        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n",
      "Classification report for Rough_silverside94:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Sheepshead_minnow:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Str_bass:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84        18\n",
      "           1       0.67      0.50      0.57         8\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.73      0.69      0.71        26\n",
      "weighted avg       0.76      0.77      0.76        26\n",
      "\n",
      "Classification report for White_mullet:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Am_eel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.48      0.48      0.48        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n",
      "Classification report for Red_eye_round_herring:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Inshore_lizardfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Atl_mackerel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Flathead_grey_mullet:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        22\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.42      0.50      0.46        26\n",
      "weighted avg       0.72      0.85      0.78        26\n",
      "\n",
      "Classification report for Silver_hake:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.71        17\n",
      "           1       0.50      0.67      0.57         9\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.64      0.66      0.64        26\n",
      "weighted avg       0.69      0.65      0.66        26\n",
      "\n",
      "Classification report for Winter_or_Yellowtail_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88        20\n",
      "           1       0.67      0.33      0.44         6\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.75      0.64      0.66        26\n",
      "weighted avg       0.79      0.81      0.78        26\n",
      "\n",
      "Classification report for Atl_herring:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Atl_cod:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Am_gizzard_shad:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Fourspine_stickleback:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Catfish_sp:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for White_perch:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        25\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Whitefish_Cor:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Pac_sand_lance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for White_catfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Atl_salmon:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8882536382536382"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MULTI OUTPUT CLASSIFIER\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "features = ml_df[['Surface_Temp','Bottom_Temp','Surface_Salinity','Bottom_Salinity','temp_strat','salt_strat']]\n",
    "## with date\n",
    "# features = ml_df[['Surface_Salinity','Bottom_Salinity','salt_strat', 'Surface_Temp','Bottom_Temp','temp_strat','date_numeric']]\n",
    "\n",
    "labels = ml_df.loc[:,'Atl_croaker_(nibea98)':'Atl_salmon'].applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the multi-output Random Forest classifier\n",
    "rf_classifier = MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "for i, species in enumerate(labels.columns):\n",
    "    accuracy = accuracy_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    # precision = precision_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    # recall = recall_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    # f1 = f1_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Classification report for {species}:\\n\", classification_report(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    # print(f\"Accuracy for {species}: {accuracy}\")\n",
    "\n",
    "# Calculate overall average accuracy across all species\n",
    "average_accuracy = np.mean(accuracies)\n",
    "average_accuracy\n",
    "\n",
    "# # Evaluate the model\n",
    "# for i, species in enumerate(labels.columns):\n",
    "#     print(f\"Classification report for {species}:\\n\", classification_report(y_test.iloc[:, i], y_pred[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atl_croaker_(nibea98)</th>\n",
       "      <th>Bay_anchovy</th>\n",
       "      <th>Black_drum_or_Spot</th>\n",
       "      <th>Black_sea_bass</th>\n",
       "      <th>Brd_striped_anchovy</th>\n",
       "      <th>Little_tunny_or_skipjack_tuna</th>\n",
       "      <th>Nor_sea_robin</th>\n",
       "      <th>Scup</th>\n",
       "      <th>Smallmouth_flounder</th>\n",
       "      <th>Southern_kingfish(nibea95)</th>\n",
       "      <th>...</th>\n",
       "      <th>Atl_cod</th>\n",
       "      <th>Am_gizzard_shad</th>\n",
       "      <th>Fourspine_stickleback</th>\n",
       "      <th>Catfish_sp</th>\n",
       "      <th>White_perch</th>\n",
       "      <th>Whitefish_Cor</th>\n",
       "      <th>Pac_sand_lance</th>\n",
       "      <th>White_catfish</th>\n",
       "      <th>Atl_salmon</th>\n",
       "      <th>mean_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.169182</td>\n",
       "      <td>0.245775</td>\n",
       "      <td>0.216902</td>\n",
       "      <td>0.336197</td>\n",
       "      <td>0.178185</td>\n",
       "      <td>0.217504</td>\n",
       "      <td>0.281813</td>\n",
       "      <td>0.239100</td>\n",
       "      <td>0.327769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227382</td>\n",
       "      <td>0.216025</td>\n",
       "      <td>0.200224</td>\n",
       "      <td>0.178484</td>\n",
       "      <td>0.271933</td>\n",
       "      <td>0.177918</td>\n",
       "      <td>0.199271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.262855</td>\n",
       "      <td>0.135667</td>\n",
       "      <td>0.193176</td>\n",
       "      <td>0.278948</td>\n",
       "      <td>0.303112</td>\n",
       "      <td>0.223461</td>\n",
       "      <td>0.219158</td>\n",
       "      <td>0.228831</td>\n",
       "      <td>0.208983</td>\n",
       "      <td>0.235956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103815</td>\n",
       "      <td>0.189447</td>\n",
       "      <td>0.184753</td>\n",
       "      <td>0.076185</td>\n",
       "      <td>0.168595</td>\n",
       "      <td>0.147804</td>\n",
       "      <td>0.192134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.118082</td>\n",
       "      <td>0.120021</td>\n",
       "      <td>0.121503</td>\n",
       "      <td>0.141464</td>\n",
       "      <td>0.065127</td>\n",
       "      <td>0.172495</td>\n",
       "      <td>0.116252</td>\n",
       "      <td>0.142972</td>\n",
       "      <td>0.113952</td>\n",
       "      <td>0.090135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161147</td>\n",
       "      <td>0.093653</td>\n",
       "      <td>0.111318</td>\n",
       "      <td>0.186349</td>\n",
       "      <td>0.170623</td>\n",
       "      <td>0.154049</td>\n",
       "      <td>0.131010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.172468</td>\n",
       "      <td>0.145090</td>\n",
       "      <td>0.157694</td>\n",
       "      <td>0.174810</td>\n",
       "      <td>0.121458</td>\n",
       "      <td>0.217678</td>\n",
       "      <td>0.124326</td>\n",
       "      <td>0.118820</td>\n",
       "      <td>0.159730</td>\n",
       "      <td>0.132719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167406</td>\n",
       "      <td>0.178825</td>\n",
       "      <td>0.251775</td>\n",
       "      <td>0.189488</td>\n",
       "      <td>0.251235</td>\n",
       "      <td>0.178732</td>\n",
       "      <td>0.165930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.101614</td>\n",
       "      <td>0.264588</td>\n",
       "      <td>0.172755</td>\n",
       "      <td>0.100444</td>\n",
       "      <td>0.114078</td>\n",
       "      <td>0.119888</td>\n",
       "      <td>0.243392</td>\n",
       "      <td>0.121365</td>\n",
       "      <td>0.153634</td>\n",
       "      <td>0.103715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184947</td>\n",
       "      <td>0.179653</td>\n",
       "      <td>0.210079</td>\n",
       "      <td>0.235389</td>\n",
       "      <td>0.100501</td>\n",
       "      <td>0.226028</td>\n",
       "      <td>0.155855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.074876</td>\n",
       "      <td>0.165452</td>\n",
       "      <td>0.109097</td>\n",
       "      <td>0.087432</td>\n",
       "      <td>0.060028</td>\n",
       "      <td>0.088293</td>\n",
       "      <td>0.079369</td>\n",
       "      <td>0.106200</td>\n",
       "      <td>0.124601</td>\n",
       "      <td>0.109707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155303</td>\n",
       "      <td>0.142397</td>\n",
       "      <td>0.041851</td>\n",
       "      <td>0.134105</td>\n",
       "      <td>0.037113</td>\n",
       "      <td>0.115469</td>\n",
       "      <td>0.115259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Atl_croaker_(nibea98)  Bay_anchovy  Black_drum_or_Spot  Black_sea_bass  \\\n",
       "0               0.270105     0.169182            0.245775        0.216902   \n",
       "1               0.262855     0.135667            0.193176        0.278948   \n",
       "2               0.118082     0.120021            0.121503        0.141464   \n",
       "3               0.172468     0.145090            0.157694        0.174810   \n",
       "4               0.101614     0.264588            0.172755        0.100444   \n",
       "5               0.074876     0.165452            0.109097        0.087432   \n",
       "\n",
       "   Brd_striped_anchovy  Little_tunny_or_skipjack_tuna  Nor_sea_robin  \\\n",
       "0             0.336197                       0.178185       0.217504   \n",
       "1             0.303112                       0.223461       0.219158   \n",
       "2             0.065127                       0.172495       0.116252   \n",
       "3             0.121458                       0.217678       0.124326   \n",
       "4             0.114078                       0.119888       0.243392   \n",
       "5             0.060028                       0.088293       0.079369   \n",
       "\n",
       "       Scup  Smallmouth_flounder  Southern_kingfish(nibea95)  ...   Atl_cod  \\\n",
       "0  0.281813             0.239100                    0.327769  ...  0.060297   \n",
       "1  0.228831             0.208983                    0.235956  ...  0.103928   \n",
       "2  0.142972             0.113952                    0.090135  ...  0.269554   \n",
       "3  0.118820             0.159730                    0.132719  ...  0.428774   \n",
       "4  0.121365             0.153634                    0.103715  ...  0.111744   \n",
       "5  0.106200             0.124601                    0.109707  ...  0.025703   \n",
       "\n",
       "   Am_gizzard_shad  Fourspine_stickleback  Catfish_sp  White_perch  \\\n",
       "0              0.0                    0.0    0.227382     0.216025   \n",
       "1              0.0                    0.0    0.103815     0.189447   \n",
       "2              0.0                    0.0    0.161147     0.093653   \n",
       "3              0.0                    0.0    0.167406     0.178825   \n",
       "4              0.0                    0.0    0.184947     0.179653   \n",
       "5              0.0                    0.0    0.155303     0.142397   \n",
       "\n",
       "   Whitefish_Cor  Pac_sand_lance  White_catfish  Atl_salmon  mean_importance  \n",
       "0       0.200224        0.178484       0.271933    0.177918         0.199271  \n",
       "1       0.184753        0.076185       0.168595    0.147804         0.192134  \n",
       "2       0.111318        0.186349       0.170623    0.154049         0.131010  \n",
       "3       0.251775        0.189488       0.251235    0.178732         0.165930  \n",
       "4       0.210079        0.235389       0.100501    0.226028         0.155855  \n",
       "5       0.041851        0.134105       0.037113    0.115469         0.115259  \n",
       "\n",
       "[6 rows x 75 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature_importance_df = pd.DataFrame() # type: ignore\n",
    "for i, species in enumerate(labels.columns):\n",
    "    importances = rf_classifier.estimators_[i].feature_importances_\n",
    "    feature_importance_df[species] = importances\n",
    "\n",
    "# Calculate mean feature importance across all species\n",
    "feature_importance_df['mean_importance'] = feature_importance_df.mean(axis=1)\n",
    "\n",
    "# # Plot feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(features.columns, feature_importance_df['mean_importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Mean Feature Importance Across All Species')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "importances\n",
    "feature_importance_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "Finding best combination of weights for model: tbd 7/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base model performance of 88.82% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomizedsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Accuracy: 0.00\n",
      "Best Hyperparameters: {'estimator__min_samples_split': 5, 'estimator__min_samples_leaf': 2, 'estimator__max_depth': None, 'estimator__bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    # 'estimator__n_estimators' : [50,100,200,500],\n",
    "    'estimator__max_depth': [None, 10, 20, 30],\n",
    "    'estimator__min_samples_split': [2, 5, 10],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4],\n",
    "    'estimator__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_classifier = MultiOutputClassifier(RandomForestClassifier())\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "randomized_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_dist, n_iter=20, cv=3, random_state=42)\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params_rand = randomized_search.best_params_\n",
    "best_model_rand = randomized_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred_best_rand = best_model_rand.predict(X_test)\n",
    "accuracy_best_rand = accuracy_score(y_test, y_pred_best_rand)\n",
    "print(f\"Best RF Accuracy: {accuracy_best_rand:.2f}\")\n",
    "print(f\"Best Hyperparameters: {best_params_rand}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters according to previous grid search: {'estimator__bootstrap': True, 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2}\n",
    "\n",
    "Best Hyperparameters from Random Search: {'estimator__min_samples_split': 5, 'estimator__min_samples_leaf': 2, 'estimator__max_depth': None, 'estimator__bootstrap': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define new grid based on Random search best params above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Atl_croaker_(nibea98):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80         7\n",
      "           1       0.94      0.89      0.92        19\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.85      0.88      0.86        26\n",
      "weighted avg       0.89      0.88      0.89        26\n",
      "\n",
      "Classification report for Bay_anchovy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.92      1.00      0.96        24\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Black_drum_or_Spot:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.88      0.96      0.92        23\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.44      0.48      0.46        26\n",
      "weighted avg       0.78      0.85      0.81        26\n",
      "\n",
      "Classification report for Black_sea_bass:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         4\n",
      "           1       0.90      0.82      0.86        22\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.62      0.66      0.63        26\n",
      "weighted avg       0.81      0.77      0.79        26\n",
      "\n",
      "Classification report for Brd_striped_anchovy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        10\n",
      "           1       0.89      1.00      0.94        16\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.94      0.90      0.92        26\n",
      "weighted avg       0.93      0.92      0.92        26\n",
      "\n",
      "Classification report for Little_tunny_or_skipjack_tuna:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Nor_sea_robin:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.92      1.00      0.96        23\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.96      0.67      0.73        26\n",
      "weighted avg       0.93      0.92      0.91        26\n",
      "\n",
      "Classification report for Scup:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         6\n",
      "           1       0.82      0.90      0.86        20\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.66      0.62      0.63        26\n",
      "weighted avg       0.74      0.77      0.75        26\n",
      "\n",
      "Classification report for Smallmouth_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.81      1.00      0.89        21\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.40      0.50      0.45        26\n",
      "weighted avg       0.65      0.81      0.72        26\n",
      "\n",
      "Classification report for Southern_kingfish(nibea95):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.29      0.36         7\n",
      "           1       0.77      0.89      0.83        19\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.64      0.59      0.60        26\n",
      "weighted avg       0.70      0.73      0.70        26\n",
      "\n",
      "Classification report for Str_sea_robin:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.53      0.67        15\n",
      "           1       0.59      0.91      0.71        11\n",
      "\n",
      "    accuracy                           0.69        26\n",
      "   macro avg       0.74      0.72      0.69        26\n",
      "weighted avg       0.76      0.69      0.69        26\n",
      "\n",
      "Classification report for Summ_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.96      1.00      0.98        25\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Summ_flounder99a:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69        15\n",
      "           1       0.56      0.45      0.50        11\n",
      "\n",
      "    accuracy                           0.62        26\n",
      "   macro avg       0.60      0.59      0.59        26\n",
      "weighted avg       0.61      0.62      0.61        26\n",
      "\n",
      "Classification report for Weakfish_Cyn:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         3\n",
      "           1       0.95      0.91      0.93        23\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.73      0.79      0.75        26\n",
      "weighted avg       0.90      0.88      0.89        26\n",
      "\n",
      "Classification report for Windowpane_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Am_butterfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.96      1.00      0.98        25\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Atl_chub_mackerel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Frigate_or_bullet_tuna:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Giant_trevally99:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        24\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.83      0.98      0.89        26\n",
      "weighted avg       0.97      0.96      0.96        26\n",
      "\n",
      "Classification report for Hogchoker_trinectes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81        18\n",
      "           1       0.57      0.50      0.53         8\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.68      0.67      0.67        26\n",
      "weighted avg       0.72      0.73      0.73        26\n",
      "\n",
      "Classification report for Nor_kingfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71         7\n",
      "           1       0.89      0.89      0.89        19\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.80      0.80      0.80        26\n",
      "weighted avg       0.85      0.85      0.85        26\n",
      "\n",
      "Classification report for Red_White_or_Spotted_hake:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Spanish_mackerel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Tautog:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.69      0.60        13\n",
      "           1       0.56      0.38      0.45        13\n",
      "\n",
      "    accuracy                           0.54        26\n",
      "   macro avg       0.54      0.54      0.53        26\n",
      "weighted avg       0.54      0.54      0.53        26\n",
      "\n",
      "Classification report for Thread_herring:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        19\n",
      "           1       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.87      0.83      0.85        26\n",
      "weighted avg       0.88      0.88      0.88        26\n",
      "\n",
      "Classification report for Atl_menhaden_LS16_or_river_herrings:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.96      0.92      0.94        25\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.48      0.46      0.47        26\n",
      "weighted avg       0.92      0.88      0.90        26\n",
      "\n",
      "Classification report for Cobia:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Cunner:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Am_conger:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        25\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.75      0.98      0.82        26\n",
      "weighted avg       0.98      0.96      0.97        26\n",
      "\n",
      "Classification report for Atl_or_nor_sand_lance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.93      0.76        14\n",
      "           1       0.83      0.42      0.56        12\n",
      "\n",
      "    accuracy                           0.69        26\n",
      "   macro avg       0.74      0.67      0.66        26\n",
      "weighted avg       0.73      0.69      0.67        26\n",
      "\n",
      "Classification report for Bluefish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.82         9\n",
      "           1       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.88      0.86      0.87        26\n",
      "weighted avg       0.88      0.88      0.88        26\n",
      "\n",
      "Classification report for Silver_anchovy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        23\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.96      0.67      0.73        26\n",
      "weighted avg       0.93      0.92      0.91        26\n",
      "\n",
      "Classification report for Seaboard_goby:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        18\n",
      "           1       1.00      0.12      0.22         8\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.86      0.56      0.53        26\n",
      "weighted avg       0.81      0.73      0.65        26\n",
      "\n",
      "Classification report for Nor_puffer:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        22\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.70      0.70      0.70        26\n",
      "weighted avg       0.85      0.85      0.85        26\n",
      "\n",
      "Classification report for Silver_perch(nibea93):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.91      0.69        11\n",
      "           1       0.88      0.47      0.61        15\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.72      0.69      0.65        26\n",
      "weighted avg       0.74      0.65      0.64        26\n",
      "\n",
      "Classification report for Sturgeon:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79        16\n",
      "           1       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.72      0.71      0.71        26\n",
      "weighted avg       0.73      0.73      0.73        26\n",
      "\n",
      "Classification report for Crested_blenny_refseq_not_full_length:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Str_burrfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Dwarf_goatfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Fourspot_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        20\n",
      "           1       0.60      0.50      0.55         6\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.73      0.70      0.71        26\n",
      "weighted avg       0.80      0.81      0.80        26\n",
      "\n",
      "Classification report for Nor_sennet95:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        21\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.40      0.50      0.45        26\n",
      "weighted avg       0.65      0.81      0.72        26\n",
      "\n",
      "Classification report for Tuna_sp:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Atl_moonfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Atl_silverside:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        16\n",
      "           1       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.89      0.87      0.88        26\n",
      "weighted avg       0.88      0.88      0.88        26\n",
      "\n",
      "Classification report for Gulf_stream_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        21\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.40      0.50      0.45        26\n",
      "weighted avg       0.65      0.81      0.72        26\n",
      "\n",
      "Classification report for Str_cusk_eel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        23\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.96      0.67      0.73        26\n",
      "weighted avg       0.93      0.92      0.91        26\n",
      "\n",
      "Classification report for Nor_stargazer:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Grey_triggerfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.46      0.50      0.48        26\n",
      "weighted avg       0.85      0.92      0.89        26\n",
      "\n",
      "Classification report for Nor_pipefish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        22\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.42      0.50      0.46        26\n",
      "weighted avg       0.72      0.85      0.78        26\n",
      "\n",
      "Classification report for Planehead_filefish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Rough_scad:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        20\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.38      0.50      0.43        26\n",
      "weighted avg       0.59      0.77      0.67        26\n",
      "\n",
      "Classification report for Str_killifish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Mummichog:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Rough_silverside94:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Sheepshead_minnow:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Str_bass:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86        18\n",
      "           1       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.78      0.76      0.77        26\n",
      "weighted avg       0.80      0.81      0.80        26\n",
      "\n",
      "Classification report for White_mullet:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Am_eel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.48      0.48      0.48        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n",
      "Classification report for Red_eye_round_herring:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Inshore_lizardfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Atl_mackerel:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Flathead_grey_mullet:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        22\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.42      0.50      0.46        26\n",
      "weighted avg       0.72      0.85      0.78        26\n",
      "\n",
      "Classification report for Silver_hake:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.71        17\n",
      "           1       0.50      0.67      0.57         9\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.64      0.66      0.64        26\n",
      "weighted avg       0.69      0.65      0.66        26\n",
      "\n",
      "Classification report for Winter_or_Yellowtail_flounder:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84        20\n",
      "           1       0.33      0.17      0.22         6\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.56      0.53      0.53        26\n",
      "weighted avg       0.68      0.73      0.70        26\n",
      "\n",
      "Classification report for Atl_herring:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Atl_cod:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Am_gizzard_shad:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Fourspine_stickleback:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Catfish_sp:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for White_perch:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.48      0.50      0.49        26\n",
      "weighted avg       0.92      0.96      0.94        26\n",
      "\n",
      "Classification report for Whitefish_Cor:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Pac_sand_lance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for White_catfish:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n",
      "Classification report for Atl_salmon:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        26\n",
      "   macro avg       1.00      1.00      1.00        26\n",
      "weighted avg       1.00      1.00      1.00        26\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8898128898128898"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ml_df[['Surface_Temp','Bottom_Temp','Surface_Salinity','Bottom_Salinity','temp_strat','salt_strat']]\n",
    "labels = ml_df.loc[:,'Atl_croaker_(nibea98)':'Atl_salmon'].applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_classifier = MultiOutputClassifier(RandomForestClassifier(n_estimators=100, min_samples_leaf=2,min_samples_split=5,\n",
    "                                                             max_depth=None,bootstrap=True,random_state=42))\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracies = []\n",
    "for i, species in enumerate(labels.columns):\n",
    "    accuracy = accuracy_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Classification report for {species}:\\n\", classification_report(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    # print(f\"Accuracy for {species}: {accuracy}\")\n",
    "\n",
    "# Calculate overall average accuracy across all species\n",
    "average_accuracy = np.mean(accuracies)\n",
    "average_accuracy\n",
    "## avg accuracy of 88.9%, improvement of 0.1% from default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
